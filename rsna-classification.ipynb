{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T23:18:08.199796Z",
     "start_time": "2020-05-18T23:18:02.287695Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "C:\\Users\\lasse\\.conda\\envs\\pytorch\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch import tensor\n",
    "from torchvision import transforms, utils\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import pydicom as dicom\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage import exposure\n",
    "\n",
    "from glob import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T23:18:08.239784Z",
     "start_time": "2020-05-18T23:18:08.200796Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    # you can continue going on here, like cuda:1 cuda:2....etc.\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T23:18:08.251780Z",
     "start_time": "2020-05-18T23:18:08.241784Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join(\".\", \"rsa-pneumonia-data\")\n",
    "\n",
    "TRAIN_IMAGES = os.path.join(DATA_DIR, \"stage_2_train_images\")\n",
    "TEST_IMAGES = os.path.join(DATA_DIR, \"stage_2_test_images\")\n",
    "PRED_MASK_DIR = os.path.join(DATA_DIR, \"stage_2_mask_images\")\n",
    "\n",
    "TRAIN_ANNOTATIONS_FILE = \"stage_2_train_labels.csv\"\n",
    "TRAIN_CLASS_FILE = \"stage_2_detailed_class_info.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T21:54:06.051948Z",
     "start_time": "2020-05-17T21:54:06.049948Z"
    }
   },
   "source": [
    "# Dataset Definition\n",
    "## Opacity Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T23:18:08.262777Z",
     "start_time": "2020-05-18T23:18:08.253780Z"
    }
   },
   "outputs": [],
   "source": [
    "class OpacityDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, image_dir, subsample, transform=None):\n",
    "        self.classes_df = pd.read_csv(csv_file)\n",
    "        if subsample is not None:\n",
    "            self.classes_df = self.classes_df[:subsample]\n",
    "        self.root_dir = root_dir\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # Convert our classes to integers!\n",
    "        self.class_dict = {\n",
    "            \"Normal\": 0,\n",
    "            \"No Lung Opacity / Not Normal\": 0,\n",
    "            \"Lung Opacity\": 1\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.classes_df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if torch.is_tensor(index):\n",
    "            index = index.tolist()\n",
    "\n",
    "        # Get the image, preprocess it for our model\n",
    "        image_path = os.path.join(\n",
    "            self.image_dir, self.classes_df.iloc[index, 0])\n",
    "        image = dicom.read_file(image_path + \".dcm\").pixel_array\n",
    "        image = image[::2, ::2]\n",
    "#         image = image/image.max()\n",
    "        \n",
    "#         imshow(image)\n",
    "#         image = (255*image).clip(0, 255).astype(np.uint8)\n",
    "        \n",
    "#         print(image)\n",
    "#         imshow(image)\n",
    "\n",
    "        image = Image.fromarray(image).convert(\"RGB\")\n",
    "        \n",
    "#         print(image)\n",
    "#         imshow(image)\n",
    "        \n",
    "        opacity_class = self.classes_df.at[index, 'class']\n",
    "        \n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        sample = {\"image\": image,\n",
    "                  \"opacity_class\": self.class_dict[opacity_class],\n",
    "                  \"class\": opacity_class}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opacity Mask Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T23:18:08.273773Z",
     "start_time": "2020-05-18T23:18:08.263776Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "class OpacityMaskDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, image_dir, subsample, transform=None):\n",
    "        self.classes_df = pd.read_csv(csv_file)\n",
    "        if subsample is not None:\n",
    "            self.classes_df = self.classes_df[:subsample]\n",
    "        self.root_dir = root_dir\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # Convert our classes to integers!\n",
    "        self.class_dict = {\n",
    "            \"Normal\": 0,\n",
    "            \"No Lung Opacity / Not Normal\": 0,\n",
    "            \"Lung Opacity\": 1\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.classes_df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if torch.is_tensor(index):\n",
    "            index = index.tolist()\n",
    "\n",
    "        # Get the image, preprocess it for our model\n",
    "#         image_path = os.path.join(\n",
    "#             self.image_dir, self.classes_df.iloc[index, 0])\n",
    "#         image = dicom.read_file(image_path + \".dcm\").pixel_array\n",
    "#         image = image[::4, ::4]\n",
    "#         image = image/image.max()\n",
    "#         image = (255*image).clip(0, 255).astype(np.uint8)\n",
    "#         image = Image.fromarray(image).convert(\"RGB\")\n",
    "        image = Image.open(os.path.join(self.image_dir, self.classes_df.iloc[index, 0] + \".jpeg\"))\n",
    "        opacity_class = self.classes_df.at[index, 'class']\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        sample = {\"image\": image,\n",
    "                  \"opacity_class\": self.class_dict[opacity_class],\n",
    "                  \"class\": opacity_class}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T02:18:39.500596Z",
     "start_time": "2020-05-19T02:18:39.438615Z"
    }
   },
   "outputs": [],
   "source": [
    "validation_split = 0.2;\n",
    "\n",
    "opacity_dataset = OpacityDataset(\n",
    "    csv_file=os.path.join(DATA_DIR, TRAIN_CLASS_FILE),\n",
    "    root_dir=DATA_DIR,\n",
    "    image_dir=TRAIN_IMAGES,\n",
    "#     subsample=10000,\n",
    "    subsample=None,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Grayscale(3),\n",
    "#         transforms.Resize(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(45),\n",
    "#         transforms.RandomAffine(20),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "\n",
    "opacity_dataset[0]\n",
    "\n",
    "dataset_size = len(opacity_dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Create samplers for data loading\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T02:18:39.804498Z",
     "start_time": "2020-05-19T02:18:39.801498Z"
    },
    "hide_input": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define our NN\n",
    "# class ConvNet(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(ConvNet, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(1, 16, (3, 3))\n",
    "#         self.pool = nn.MaxPool2d((2, 2), 2)\n",
    "#         self.conv2 = nn.Conv2d(16, 32, (3, 3))\n",
    "#         self.conv3 = nn.Conv2d(32, 64, (3, 3))\n",
    "#         self.conv4 = nn.Conv2d(64, 128, (3, 3))\n",
    "#         self.linear1 = nn.Linear(25088, 4086)\n",
    "#         self.linear3 = nn.Linear(4086, 2)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.pool(F.relu(self.conv1(x)))\n",
    "#         x = self.pool(F.relu(self.conv2(x)))\n",
    "#         x = self.pool(F.relu(self.conv3(x)))\n",
    "#         x = self.pool(F.relu(self.conv4(x)))\n",
    "#         x = x.view(x.size()[0], -1)\n",
    "#         x = F.relu(self.linear1(x))\n",
    "#         x = self.linear3(x)\n",
    "#         return x\n",
    "    \n",
    "# class AlexNet(nn.Module):\n",
    "#     def __init__(self, num_classes=2):\n",
    "#         super(AlexNet, self).__init__()\n",
    "#         self.features = nn.Sequential(\n",
    "#             nn.Conv2d(1, 64, kernel_size=11, stride=4, padding=2),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "#             nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "#             nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "#         )\n",
    "#         self.classifier = nn.Sequential(\n",
    "#             nn.Dropout(),\n",
    "#             nn.Linear(256 * 7 * 7, 4096),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Dropout(),\n",
    "#             nn.Linear(4096, 4096),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Linear(4096, num_classes),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.features(x)\n",
    "#         x = x.view(x.size(0), 256 * 7 * 7)\n",
    "#         x = self.classifier(x)\n",
    "#         return x\n",
    "\n",
    "# model = AlexNet()\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T23:49:13.018378Z",
     "start_time": "2020-05-05T23:49:13.015379Z"
    },
    "deletable": false,
    "editable": false,
    "hide_input": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "del model\n",
    "torch.cuda.ipc_collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T02:18:40.145388Z",
     "start_time": "2020-05-19T02:18:40.143389Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "epochs = 20\n",
    "num_classes = 2\n",
    "batch_size = 12\n",
    "learning_rate = .001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T21:08:09.715215Z",
     "start_time": "2020-05-21T21:08:09.337337Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "feature_num = model.fc.in_features\n",
    "model.fc = nn.Linear(feature_num, num_classes)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T02:18:40.929137Z",
     "start_time": "2020-05-19T02:18:40.927137Z"
    }
   },
   "outputs": [],
   "source": [
    "# model = torchvision.models.vgg11(pretrained=False)\n",
    "# model.fc = nn.Linear(4096, num_classes)\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T02:18:41.444970Z",
     "start_time": "2020-05-19T02:18:41.441971Z"
    }
   },
   "outputs": [],
   "source": [
    "# model = torchvision.models.alexnet(pretrained=False)\n",
    "# model.fc = nn.Linear(4096, num_classes)\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T21:08:14.707611Z",
     "start_time": "2020-05-21T21:08:14.699614Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    opacity_dataset, \n",
    "    batch_size=batch_size, \n",
    "    sampler=train_sampler,\n",
    "    num_workers=0\n",
    ")\n",
    "validation_loader = torch.utils.data.DataLoader(\n",
    "    opacity_dataset, \n",
    "    batch_size=batch_size,\n",
    "    sampler=valid_sampler,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions\n",
    "## Tensor Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T21:08:15.742279Z",
     "start_time": "2020-05-21T21:08:15.738280Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_num_from_tensor(tensorItem):\n",
    "    return tensorItem.cuda().cpu().numpy().item()\n",
    "\n",
    "def get_numpy_from_tensor(tensorItem):\n",
    "    return tensorItem.cuda().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T21:08:20.522744Z",
     "start_time": "2020-05-21T21:08:20.515745Z"
    }
   },
   "outputs": [],
   "source": [
    "def correct_pred_sum(y_pred, y_test):\n",
    "    y_pred_softmax = torch.log_softmax(y_pred, dim=1)\n",
    "    _, y_pred_tags = torch.max(y_pred_softmax, dim=1)\n",
    "\n",
    "    correct_pred = (y_pred_tags == y_test).float()\n",
    "    return correct_pred.sum()\n",
    "\n",
    "def multi_acc(y_pred, y_test):\n",
    "    y_pred_softmax = torch.log_softmax(y_pred, dim=1)\n",
    "    _, y_pred_tags = torch.max(y_pred_softmax, dim=1)\n",
    "\n",
    "    correct_pred = (y_pred_tags == y_test).float()\n",
    "    acc = correct_pred.sum() / len(correct_pred)\n",
    "    acc = acc * 100\n",
    "\n",
    "    return get_num_from_tensor(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T21:58:31.870537Z",
     "start_time": "2020-05-17T21:58:31.867538Z"
    }
   },
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T05:28:31.034948Z",
     "start_time": "2020-05-21T21:08:34.506250Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    50] loss: 0.638 training_accuracy: 66.67\n",
      "[1,   100] loss: 0.551 training_accuracy: 75.00\n",
      "[1,   150] loss: 0.534 training_accuracy: 66.67\n",
      "[1,   200] loss: 0.549 training_accuracy: 83.33\n",
      "[1,   250] loss: 0.502 training_accuracy: 66.67\n",
      "[1,   300] loss: 0.559 training_accuracy: 83.33\n",
      "[1,   350] loss: 0.527 training_accuracy: 83.33\n",
      "[1,   400] loss: 0.538 training_accuracy: 75.00\n",
      "[1,   450] loss: 0.502 training_accuracy: 91.67\n",
      "[1,   500] loss: 0.497 training_accuracy: 75.00\n",
      "[1,   550] loss: 0.564 training_accuracy: 75.00\n",
      "[1,   600] loss: 0.474 training_accuracy: 66.67\n",
      "[1,   650] loss: 0.505 training_accuracy: 66.67\n",
      "[1,   700] loss: 0.475 training_accuracy: 83.33\n",
      "[1,   750] loss: 0.526 training_accuracy: 66.67\n",
      "[1,   800] loss: 0.483 training_accuracy: 91.67\n",
      "[1,   850] loss: 0.476 training_accuracy: 75.00\n",
      "[1,   900] loss: 0.450 training_accuracy: 75.00\n",
      "[1,   950] loss: 0.480 training_accuracy: 75.00\n",
      "[1,  1000] loss: 0.453 training_accuracy: 50.00\n",
      "[1,  1050] loss: 0.530 training_accuracy: 83.33\n",
      "[1,  1100] loss: 0.431 training_accuracy: 100.00\n",
      "[1,  1150] loss: 0.505 training_accuracy: 83.33\n",
      "[1,  1200] loss: 0.465 training_accuracy: 83.33\n",
      "[1,  1250] loss: 0.466 training_accuracy: 83.33\n",
      "[1,  1300] loss: 0.510 training_accuracy: 83.33\n",
      "[1,  1350] loss: 0.485 training_accuracy: 83.33\n",
      "[1,  1400] loss: 0.445 training_accuracy: 75.00\n",
      "[1,  1450] loss: 0.463 training_accuracy: 91.67\n",
      "[1,  1500] loss: 0.424 training_accuracy: 100.00\n",
      "[1,  1550] loss: 0.438 training_accuracy: 66.67\n",
      "[1,  1600] loss: 0.428 training_accuracy: 75.00\n",
      "[1,  1650] loss: 0.523 training_accuracy: 58.33\n",
      "[1,  1700] loss: 0.452 training_accuracy: 91.67\n",
      "[1,  1750] loss: 0.461 training_accuracy: 91.67\n",
      "[1,  1800] loss: 0.479 training_accuracy: 66.67\n",
      "[1,  1850] loss: 0.498 training_accuracy: 83.33\n",
      "[1,  1900] loss: 0.451 training_accuracy: 75.00\n",
      "[1,  1950] loss: 0.500 training_accuracy: 75.00\n",
      "[1,  2000] loss: 0.485 training_accuracy: 66.67\n",
      "Epoch [1] Loss: 0.487 Training Accuracy: 77.273 Validation Accuracy: 77.546 \n",
      "------------------------------------------------------------------------\n",
      "[2,    50] loss: 0.501 training_accuracy: 75.00\n",
      "[2,   100] loss: 0.445 training_accuracy: 66.67\n",
      "[2,   150] loss: 0.466 training_accuracy: 91.67\n",
      "[2,   200] loss: 0.450 training_accuracy: 66.67\n",
      "[2,   250] loss: 0.469 training_accuracy: 83.33\n",
      "[2,   300] loss: 0.469 training_accuracy: 91.67\n",
      "[2,   350] loss: 0.436 training_accuracy: 100.00\n",
      "[2,   400] loss: 0.446 training_accuracy: 83.33\n",
      "[2,   450] loss: 0.479 training_accuracy: 83.33\n",
      "[2,   500] loss: 0.494 training_accuracy: 58.33\n",
      "[2,   550] loss: 0.469 training_accuracy: 75.00\n",
      "[2,   600] loss: 0.511 training_accuracy: 75.00\n",
      "[2,   650] loss: 0.432 training_accuracy: 91.67\n",
      "[2,   700] loss: 0.465 training_accuracy: 58.33\n",
      "[2,   750] loss: 0.486 training_accuracy: 75.00\n",
      "[2,   800] loss: 0.434 training_accuracy: 75.00\n",
      "[2,   850] loss: 0.459 training_accuracy: 83.33\n",
      "[2,   900] loss: 0.466 training_accuracy: 66.67\n",
      "[2,   950] loss: 0.444 training_accuracy: 91.67\n",
      "[2,  1000] loss: 0.457 training_accuracy: 91.67\n",
      "[2,  1050] loss: 0.447 training_accuracy: 91.67\n",
      "[2,  1100] loss: 0.428 training_accuracy: 83.33\n",
      "[2,  1150] loss: 0.416 training_accuracy: 75.00\n",
      "[2,  1200] loss: 0.383 training_accuracy: 83.33\n",
      "[2,  1250] loss: 0.467 training_accuracy: 83.33\n",
      "[2,  1300] loss: 0.450 training_accuracy: 75.00\n",
      "[2,  1350] loss: 0.433 training_accuracy: 83.33\n",
      "[2,  1400] loss: 0.433 training_accuracy: 58.33\n",
      "[2,  1450] loss: 0.421 training_accuracy: 91.67\n",
      "[2,  1500] loss: 0.439 training_accuracy: 75.00\n",
      "[2,  1550] loss: 0.456 training_accuracy: 83.33\n",
      "[2,  1600] loss: 0.425 training_accuracy: 75.00\n",
      "[2,  1650] loss: 0.481 training_accuracy: 66.67\n",
      "[2,  1700] loss: 0.470 training_accuracy: 66.67\n",
      "[2,  1750] loss: 0.461 training_accuracy: 83.33\n",
      "[2,  1800] loss: 0.403 training_accuracy: 91.67\n",
      "[2,  1850] loss: 0.445 training_accuracy: 91.67\n",
      "[2,  1900] loss: 0.444 training_accuracy: 66.67\n",
      "[2,  1950] loss: 0.433 training_accuracy: 83.33\n",
      "[2,  2000] loss: 0.468 training_accuracy: 91.67\n",
      "Epoch [2] Loss: 0.452 Training Accuracy: 78.261 Validation Accuracy: 78.830 \n",
      "------------------------------------------------------------------------\n",
      "[3,    50] loss: 0.450 training_accuracy: 75.00\n",
      "[3,   100] loss: 0.400 training_accuracy: 83.33\n",
      "[3,   150] loss: 0.467 training_accuracy: 75.00\n",
      "[3,   200] loss: 0.409 training_accuracy: 75.00\n",
      "[3,   250] loss: 0.423 training_accuracy: 83.33\n",
      "[3,   300] loss: 0.424 training_accuracy: 83.33\n",
      "[3,   350] loss: 0.427 training_accuracy: 91.67\n",
      "[3,   400] loss: 0.403 training_accuracy: 91.67\n",
      "[3,   450] loss: 0.503 training_accuracy: 75.00\n",
      "[3,   500] loss: 0.460 training_accuracy: 66.67\n",
      "[3,   550] loss: 0.399 training_accuracy: 91.67\n",
      "[3,   600] loss: 0.394 training_accuracy: 91.67\n",
      "[3,   650] loss: 0.409 training_accuracy: 66.67\n",
      "[3,   700] loss: 0.412 training_accuracy: 75.00\n",
      "[3,   750] loss: 0.471 training_accuracy: 91.67\n",
      "[3,   800] loss: 0.454 training_accuracy: 75.00\n",
      "[3,   850] loss: 0.443 training_accuracy: 75.00\n",
      "[3,   900] loss: 0.443 training_accuracy: 66.67\n",
      "[3,   950] loss: 0.412 training_accuracy: 83.33\n",
      "[3,  1000] loss: 0.460 training_accuracy: 83.33\n",
      "[3,  1050] loss: 0.404 training_accuracy: 91.67\n",
      "[3,  1100] loss: 0.438 training_accuracy: 75.00\n",
      "[3,  1150] loss: 0.387 training_accuracy: 83.33\n",
      "[3,  1200] loss: 0.428 training_accuracy: 91.67\n",
      "[3,  1250] loss: 0.421 training_accuracy: 91.67\n",
      "[3,  1300] loss: 0.463 training_accuracy: 75.00\n",
      "[3,  1350] loss: 0.450 training_accuracy: 83.33\n",
      "[3,  1400] loss: 0.416 training_accuracy: 66.67\n",
      "[3,  1450] loss: 0.489 training_accuracy: 75.00\n",
      "[3,  1500] loss: 0.414 training_accuracy: 66.67\n",
      "[3,  1550] loss: 0.420 training_accuracy: 58.33\n",
      "[3,  1600] loss: 0.446 training_accuracy: 58.33\n",
      "[3,  1650] loss: 0.456 training_accuracy: 83.33\n",
      "[3,  1700] loss: 0.455 training_accuracy: 91.67\n",
      "[3,  1750] loss: 0.470 training_accuracy: 83.33\n",
      "[3,  1800] loss: 0.430 training_accuracy: 66.67\n",
      "[3,  1850] loss: 0.423 training_accuracy: 66.67\n",
      "[3,  1900] loss: 0.473 training_accuracy: 75.00\n",
      "[3,  1950] loss: 0.436 training_accuracy: 91.67\n",
      "[3,  2000] loss: 0.413 training_accuracy: 91.67\n",
      "Epoch [3] Loss: 0.442 Training Accuracy: 79.894 Validation Accuracy: 80.633 \n",
      "------------------------------------------------------------------------\n",
      "[4,    50] loss: 0.474 training_accuracy: 75.00\n",
      "[4,   100] loss: 0.444 training_accuracy: 91.67\n",
      "[4,   150] loss: 0.443 training_accuracy: 75.00\n",
      "[4,   200] loss: 0.423 training_accuracy: 91.67\n",
      "[4,   250] loss: 0.433 training_accuracy: 83.33\n",
      "[4,   300] loss: 0.461 training_accuracy: 83.33\n",
      "[4,   350] loss: 0.417 training_accuracy: 83.33\n",
      "[4,   400] loss: 0.437 training_accuracy: 100.00\n",
      "[4,   450] loss: 0.424 training_accuracy: 91.67\n",
      "[4,   500] loss: 0.429 training_accuracy: 75.00\n",
      "[4,   550] loss: 0.429 training_accuracy: 83.33\n",
      "[4,   600] loss: 0.447 training_accuracy: 41.67\n",
      "[4,   650] loss: 0.439 training_accuracy: 83.33\n",
      "[4,   700] loss: 0.424 training_accuracy: 83.33\n",
      "[4,   750] loss: 0.441 training_accuracy: 58.33\n",
      "[4,   800] loss: 0.464 training_accuracy: 83.33\n",
      "[4,   850] loss: 0.453 training_accuracy: 58.33\n",
      "[4,   900] loss: 0.454 training_accuracy: 83.33\n",
      "[4,   950] loss: 0.451 training_accuracy: 75.00\n",
      "[4,  1000] loss: 0.423 training_accuracy: 100.00\n",
      "[4,  1050] loss: 0.385 training_accuracy: 66.67\n",
      "[4,  1100] loss: 0.408 training_accuracy: 83.33\n",
      "[4,  1150] loss: 0.426 training_accuracy: 91.67\n",
      "[4,  1200] loss: 0.418 training_accuracy: 100.00\n",
      "[4,  1250] loss: 0.450 training_accuracy: 75.00\n",
      "[4,  1300] loss: 0.396 training_accuracy: 91.67\n",
      "[4,  1350] loss: 0.439 training_accuracy: 83.33\n",
      "[4,  1400] loss: 0.492 training_accuracy: 75.00\n",
      "[4,  1450] loss: 0.413 training_accuracy: 75.00\n",
      "[4,  1500] loss: 0.418 training_accuracy: 91.67\n",
      "[4,  1550] loss: 0.428 training_accuracy: 100.00\n",
      "[4,  1600] loss: 0.422 training_accuracy: 83.33\n",
      "[4,  1650] loss: 0.445 training_accuracy: 50.00\n",
      "[4,  1700] loss: 0.438 training_accuracy: 83.33\n",
      "[4,  1750] loss: 0.406 training_accuracy: 66.67\n",
      "[4,  1800] loss: 0.414 training_accuracy: 66.67\n",
      "[4,  1850] loss: 0.383 training_accuracy: 75.00\n",
      "[4,  1900] loss: 0.415 training_accuracy: 91.67\n",
      "[4,  1950] loss: 0.422 training_accuracy: 83.33\n",
      "[4,  2000] loss: 0.423 training_accuracy: 100.00\n",
      "Epoch [4] Loss: 0.419 Training Accuracy: 80.597 Validation Accuracy: 80.721 \n",
      "------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5,    50] loss: 0.413 training_accuracy: 91.67\n",
      "[5,   100] loss: 0.426 training_accuracy: 75.00\n",
      "[5,   150] loss: 0.420 training_accuracy: 100.00\n",
      "[5,   200] loss: 0.423 training_accuracy: 83.33\n",
      "[5,   250] loss: 0.430 training_accuracy: 75.00\n",
      "[5,   300] loss: 0.451 training_accuracy: 91.67\n",
      "[5,   350] loss: 0.405 training_accuracy: 75.00\n",
      "[5,   400] loss: 0.436 training_accuracy: 83.33\n",
      "[5,   450] loss: 0.399 training_accuracy: 75.00\n",
      "[5,   500] loss: 0.402 training_accuracy: 83.33\n",
      "[5,   550] loss: 0.409 training_accuracy: 83.33\n",
      "[5,   600] loss: 0.433 training_accuracy: 91.67\n",
      "[5,   650] loss: 0.422 training_accuracy: 91.67\n",
      "[5,   700] loss: 0.400 training_accuracy: 83.33\n",
      "[5,   750] loss: 0.384 training_accuracy: 91.67\n",
      "[5,   800] loss: 0.429 training_accuracy: 91.67\n",
      "[5,   850] loss: 0.398 training_accuracy: 91.67\n",
      "[5,   900] loss: 0.402 training_accuracy: 83.33\n",
      "[5,   950] loss: 0.456 training_accuracy: 75.00\n",
      "[5,  1000] loss: 0.455 training_accuracy: 83.33\n",
      "[5,  1050] loss: 0.428 training_accuracy: 83.33\n",
      "[5,  1100] loss: 0.411 training_accuracy: 75.00\n",
      "[5,  1150] loss: 0.452 training_accuracy: 75.00\n",
      "[5,  1200] loss: 0.426 training_accuracy: 83.33\n",
      "[5,  1250] loss: 0.434 training_accuracy: 58.33\n",
      "[5,  1300] loss: 0.460 training_accuracy: 58.33\n",
      "[5,  1350] loss: 0.393 training_accuracy: 91.67\n",
      "[5,  1400] loss: 0.468 training_accuracy: 83.33\n",
      "[5,  1450] loss: 0.397 training_accuracy: 91.67\n",
      "[5,  1500] loss: 0.408 training_accuracy: 66.67\n",
      "[5,  1550] loss: 0.423 training_accuracy: 100.00\n",
      "[5,  1600] loss: 0.433 training_accuracy: 75.00\n",
      "[5,  1650] loss: 0.442 training_accuracy: 91.67\n",
      "[5,  1700] loss: 0.460 training_accuracy: 75.00\n",
      "[5,  1750] loss: 0.405 training_accuracy: 75.00\n",
      "[5,  1800] loss: 0.416 training_accuracy: 83.33\n",
      "[5,  1850] loss: 0.440 training_accuracy: 83.33\n",
      "[5,  1900] loss: 0.408 training_accuracy: 91.67\n",
      "[5,  1950] loss: 0.427 training_accuracy: 75.00\n",
      "[5,  2000] loss: 0.444 training_accuracy: 91.67\n",
      "Epoch [5] Loss: 0.413 Training Accuracy: 81.114 Validation Accuracy: 80.980 \n",
      "------------------------------------------------------------------------\n",
      "[6,    50] loss: 0.403 training_accuracy: 91.67\n",
      "[6,   100] loss: 0.435 training_accuracy: 75.00\n",
      "[6,   150] loss: 0.382 training_accuracy: 83.33\n",
      "[6,   200] loss: 0.395 training_accuracy: 100.00\n",
      "[6,   250] loss: 0.439 training_accuracy: 83.33\n",
      "[6,   300] loss: 0.425 training_accuracy: 66.67\n",
      "[6,   350] loss: 0.426 training_accuracy: 91.67\n",
      "[6,   400] loss: 0.405 training_accuracy: 75.00\n",
      "[6,   450] loss: 0.464 training_accuracy: 91.67\n",
      "[6,   500] loss: 0.416 training_accuracy: 83.33\n",
      "[6,   550] loss: 0.455 training_accuracy: 91.67\n",
      "[6,   600] loss: 0.423 training_accuracy: 83.33\n",
      "[6,   650] loss: 0.407 training_accuracy: 100.00\n",
      "[6,   700] loss: 0.405 training_accuracy: 83.33\n",
      "[6,   750] loss: 0.412 training_accuracy: 91.67\n",
      "[6,   800] loss: 0.406 training_accuracy: 75.00\n",
      "[6,   850] loss: 0.396 training_accuracy: 75.00\n",
      "[6,   900] loss: 0.420 training_accuracy: 66.67\n",
      "[6,   950] loss: 0.413 training_accuracy: 83.33\n",
      "[6,  1000] loss: 0.453 training_accuracy: 75.00\n",
      "[6,  1050] loss: 0.436 training_accuracy: 75.00\n",
      "[6,  1100] loss: 0.386 training_accuracy: 83.33\n",
      "[6,  1150] loss: 0.426 training_accuracy: 83.33\n",
      "[6,  1200] loss: 0.407 training_accuracy: 83.33\n",
      "[6,  1250] loss: 0.387 training_accuracy: 91.67\n",
      "[6,  1300] loss: 0.419 training_accuracy: 75.00\n",
      "[6,  1350] loss: 0.380 training_accuracy: 91.67\n",
      "[6,  1400] loss: 0.382 training_accuracy: 83.33\n",
      "[6,  1450] loss: 0.460 training_accuracy: 83.33\n",
      "[6,  1500] loss: 0.361 training_accuracy: 75.00\n",
      "[6,  1550] loss: 0.411 training_accuracy: 75.00\n",
      "[6,  1600] loss: 0.449 training_accuracy: 83.33\n",
      "[6,  1650] loss: 0.436 training_accuracy: 91.67\n",
      "[6,  1700] loss: 0.425 training_accuracy: 83.33\n",
      "[6,  1750] loss: 0.415 training_accuracy: 75.00\n",
      "[6,  1800] loss: 0.401 training_accuracy: 83.33\n",
      "[6,  1850] loss: 0.420 training_accuracy: 83.33\n",
      "[6,  1900] loss: 0.408 training_accuracy: 83.33\n",
      "[6,  1950] loss: 0.420 training_accuracy: 83.33\n",
      "[6,  2000] loss: 0.459 training_accuracy: 91.67\n",
      "Epoch [6] Loss: 0.406 Training Accuracy: 81.510 Validation Accuracy: 81.757 \n",
      "------------------------------------------------------------------------\n",
      "[7,    50] loss: 0.388 training_accuracy: 100.00\n",
      "[7,   100] loss: 0.426 training_accuracy: 75.00\n",
      "[7,   150] loss: 0.442 training_accuracy: 75.00\n",
      "[7,   200] loss: 0.398 training_accuracy: 91.67\n",
      "[7,   250] loss: 0.390 training_accuracy: 91.67\n",
      "[7,   300] loss: 0.414 training_accuracy: 100.00\n",
      "[7,   350] loss: 0.424 training_accuracy: 83.33\n",
      "[7,   400] loss: 0.421 training_accuracy: 83.33\n",
      "[7,   450] loss: 0.437 training_accuracy: 75.00\n",
      "[7,   500] loss: 0.424 training_accuracy: 100.00\n",
      "[7,   550] loss: 0.407 training_accuracy: 83.33\n",
      "[7,   600] loss: 0.407 training_accuracy: 58.33\n",
      "[7,   650] loss: 0.391 training_accuracy: 91.67\n",
      "[7,   700] loss: 0.431 training_accuracy: 66.67\n",
      "[7,   750] loss: 0.433 training_accuracy: 75.00\n",
      "[7,   800] loss: 0.381 training_accuracy: 83.33\n",
      "[7,   850] loss: 0.438 training_accuracy: 33.33\n",
      "[7,   900] loss: 0.431 training_accuracy: 75.00\n",
      "[7,   950] loss: 0.379 training_accuracy: 75.00\n",
      "[7,  1000] loss: 0.394 training_accuracy: 100.00\n",
      "[7,  1050] loss: 0.416 training_accuracy: 100.00\n",
      "[7,  1100] loss: 0.421 training_accuracy: 75.00\n",
      "[7,  1150] loss: 0.395 training_accuracy: 83.33\n",
      "[7,  1200] loss: 0.366 training_accuracy: 83.33\n",
      "[7,  1250] loss: 0.428 training_accuracy: 75.00\n",
      "[7,  1300] loss: 0.431 training_accuracy: 91.67\n",
      "[7,  1350] loss: 0.403 training_accuracy: 75.00\n",
      "[7,  1400] loss: 0.442 training_accuracy: 75.00\n",
      "[7,  1450] loss: 0.453 training_accuracy: 83.33\n",
      "[7,  1500] loss: 0.431 training_accuracy: 75.00\n",
      "[7,  1550] loss: 0.383 training_accuracy: 75.00\n",
      "[7,  1600] loss: 0.392 training_accuracy: 75.00\n",
      "[7,  1650] loss: 0.401 training_accuracy: 75.00\n",
      "[7,  1700] loss: 0.422 training_accuracy: 91.67\n",
      "[7,  1750] loss: 0.408 training_accuracy: 91.67\n",
      "[7,  1800] loss: 0.393 training_accuracy: 100.00\n",
      "[7,  1850] loss: 0.436 training_accuracy: 66.67\n",
      "[7,  1900] loss: 0.408 training_accuracy: 83.33\n",
      "[7,  1950] loss: 0.423 training_accuracy: 66.67\n",
      "[7,  2000] loss: 0.421 training_accuracy: 75.00\n",
      "Epoch [7] Loss: 0.401 Training Accuracy: 81.676 Validation Accuracy: 81.746 \n",
      "------------------------------------------------------------------------\n",
      "[8,    50] loss: 0.422 training_accuracy: 66.67\n",
      "[8,   100] loss: 0.440 training_accuracy: 83.33\n",
      "[8,   150] loss: 0.406 training_accuracy: 100.00\n",
      "[8,   200] loss: 0.436 training_accuracy: 75.00\n",
      "[8,   250] loss: 0.432 training_accuracy: 75.00\n",
      "[8,   300] loss: 0.381 training_accuracy: 58.33\n",
      "[8,   350] loss: 0.426 training_accuracy: 75.00\n",
      "[8,   400] loss: 0.411 training_accuracy: 75.00\n",
      "[8,   450] loss: 0.434 training_accuracy: 75.00\n",
      "[8,   500] loss: 0.405 training_accuracy: 75.00\n",
      "[8,   550] loss: 0.408 training_accuracy: 91.67\n",
      "[8,   600] loss: 0.395 training_accuracy: 91.67\n",
      "[8,   650] loss: 0.446 training_accuracy: 75.00\n",
      "[8,   700] loss: 0.361 training_accuracy: 91.67\n",
      "[8,   750] loss: 0.365 training_accuracy: 83.33\n",
      "[8,   800] loss: 0.413 training_accuracy: 83.33\n",
      "[8,   850] loss: 0.377 training_accuracy: 100.00\n",
      "[8,   900] loss: 0.411 training_accuracy: 83.33\n",
      "[8,   950] loss: 0.424 training_accuracy: 75.00\n",
      "[8,  1000] loss: 0.407 training_accuracy: 66.67\n",
      "[8,  1050] loss: 0.355 training_accuracy: 100.00\n",
      "[8,  1100] loss: 0.406 training_accuracy: 83.33\n",
      "[8,  1150] loss: 0.400 training_accuracy: 83.33\n",
      "[8,  1200] loss: 0.391 training_accuracy: 58.33\n",
      "[8,  1250] loss: 0.442 training_accuracy: 83.33\n",
      "[8,  1300] loss: 0.432 training_accuracy: 91.67\n",
      "[8,  1350] loss: 0.416 training_accuracy: 75.00\n",
      "[8,  1400] loss: 0.374 training_accuracy: 91.67\n",
      "[8,  1450] loss: 0.411 training_accuracy: 75.00\n",
      "[8,  1500] loss: 0.398 training_accuracy: 75.00\n",
      "[8,  1550] loss: 0.388 training_accuracy: 75.00\n",
      "[8,  1600] loss: 0.408 training_accuracy: 91.67\n",
      "[8,  1650] loss: 0.402 training_accuracy: 100.00\n",
      "[8,  1700] loss: 0.453 training_accuracy: 83.33\n",
      "[8,  1750] loss: 0.412 training_accuracy: 83.33\n",
      "[8,  1800] loss: 0.391 training_accuracy: 75.00\n",
      "[8,  1850] loss: 0.389 training_accuracy: 83.33\n",
      "[8,  1900] loss: 0.382 training_accuracy: 91.67\n",
      "[8,  1950] loss: 0.409 training_accuracy: 66.67\n",
      "[8,  2000] loss: 0.415 training_accuracy: 58.33\n",
      "Epoch [8] Loss: 0.400 Training Accuracy: 81.936 Validation Accuracy: 81.647 \n",
      "------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9,    50] loss: 0.411 training_accuracy: 91.67\n",
      "[9,   100] loss: 0.379 training_accuracy: 66.67\n",
      "[9,   150] loss: 0.396 training_accuracy: 91.67\n",
      "[9,   200] loss: 0.398 training_accuracy: 83.33\n",
      "[9,   250] loss: 0.437 training_accuracy: 75.00\n",
      "[9,   300] loss: 0.403 training_accuracy: 83.33\n",
      "[9,   350] loss: 0.400 training_accuracy: 91.67\n",
      "[9,   400] loss: 0.427 training_accuracy: 75.00\n",
      "[9,   450] loss: 0.374 training_accuracy: 91.67\n",
      "[9,   500] loss: 0.360 training_accuracy: 75.00\n",
      "[9,   550] loss: 0.401 training_accuracy: 83.33\n",
      "[9,   600] loss: 0.416 training_accuracy: 75.00\n",
      "[9,   650] loss: 0.406 training_accuracy: 75.00\n",
      "[9,   700] loss: 0.377 training_accuracy: 83.33\n",
      "[9,   750] loss: 0.402 training_accuracy: 83.33\n",
      "[9,   800] loss: 0.400 training_accuracy: 66.67\n",
      "[9,   850] loss: 0.420 training_accuracy: 91.67\n",
      "[9,   900] loss: 0.401 training_accuracy: 83.33\n",
      "[9,   950] loss: 0.408 training_accuracy: 91.67\n",
      "[9,  1000] loss: 0.387 training_accuracy: 75.00\n",
      "[9,  1050] loss: 0.409 training_accuracy: 83.33\n",
      "[9,  1100] loss: 0.423 training_accuracy: 83.33\n",
      "[9,  1150] loss: 0.368 training_accuracy: 83.33\n",
      "[9,  1200] loss: 0.365 training_accuracy: 91.67\n",
      "[9,  1250] loss: 0.417 training_accuracy: 75.00\n",
      "[9,  1300] loss: 0.397 training_accuracy: 75.00\n",
      "[9,  1350] loss: 0.411 training_accuracy: 75.00\n",
      "[9,  1400] loss: 0.425 training_accuracy: 75.00\n",
      "[9,  1450] loss: 0.419 training_accuracy: 75.00\n",
      "[9,  1500] loss: 0.397 training_accuracy: 83.33\n",
      "[9,  1550] loss: 0.401 training_accuracy: 75.00\n",
      "[9,  1600] loss: 0.420 training_accuracy: 83.33\n",
      "[9,  1650] loss: 0.362 training_accuracy: 75.00\n",
      "[9,  1700] loss: 0.426 training_accuracy: 66.67\n",
      "[9,  1750] loss: 0.399 training_accuracy: 66.67\n",
      "[9,  1800] loss: 0.414 training_accuracy: 66.67\n",
      "[9,  1850] loss: 0.407 training_accuracy: 83.33\n",
      "[9,  1900] loss: 0.398 training_accuracy: 83.33\n",
      "[9,  1950] loss: 0.353 training_accuracy: 83.33\n",
      "[9,  2000] loss: 0.408 training_accuracy: 75.00\n",
      "Epoch [9] Loss: 0.394 Training Accuracy: 81.866 Validation Accuracy: 81.729 \n",
      "------------------------------------------------------------------------\n",
      "[10,    50] loss: 0.409 training_accuracy: 75.00\n",
      "[10,   100] loss: 0.375 training_accuracy: 83.33\n",
      "[10,   150] loss: 0.412 training_accuracy: 83.33\n",
      "[10,   200] loss: 0.408 training_accuracy: 91.67\n",
      "[10,   250] loss: 0.372 training_accuracy: 100.00\n",
      "[10,   300] loss: 0.404 training_accuracy: 91.67\n",
      "[10,   350] loss: 0.436 training_accuracy: 75.00\n",
      "[10,   400] loss: 0.392 training_accuracy: 75.00\n",
      "[10,   450] loss: 0.388 training_accuracy: 75.00\n",
      "[10,   500] loss: 0.405 training_accuracy: 75.00\n",
      "[10,   550] loss: 0.373 training_accuracy: 75.00\n",
      "[10,   600] loss: 0.375 training_accuracy: 75.00\n",
      "[10,   650] loss: 0.382 training_accuracy: 75.00\n",
      "[10,   700] loss: 0.409 training_accuracy: 83.33\n",
      "[10,   750] loss: 0.377 training_accuracy: 75.00\n",
      "[10,   800] loss: 0.376 training_accuracy: 83.33\n",
      "[10,   850] loss: 0.349 training_accuracy: 91.67\n",
      "[10,   900] loss: 0.380 training_accuracy: 75.00\n",
      "[10,   950] loss: 0.418 training_accuracy: 91.67\n",
      "[10,  1000] loss: 0.392 training_accuracy: 91.67\n",
      "[10,  1050] loss: 0.395 training_accuracy: 91.67\n",
      "[10,  1100] loss: 0.375 training_accuracy: 100.00\n",
      "[10,  1150] loss: 0.420 training_accuracy: 66.67\n",
      "[10,  1200] loss: 0.387 training_accuracy: 100.00\n",
      "[10,  1250] loss: 0.383 training_accuracy: 91.67\n",
      "[10,  1300] loss: 0.426 training_accuracy: 91.67\n",
      "[10,  1350] loss: 0.429 training_accuracy: 83.33\n",
      "[10,  1400] loss: 0.398 training_accuracy: 75.00\n",
      "[10,  1450] loss: 0.374 training_accuracy: 75.00\n",
      "[10,  1500] loss: 0.387 training_accuracy: 83.33\n",
      "[10,  1550] loss: 0.419 training_accuracy: 75.00\n",
      "[10,  1600] loss: 0.390 training_accuracy: 66.67\n",
      "[10,  1650] loss: 0.408 training_accuracy: 91.67\n",
      "[10,  1700] loss: 0.421 training_accuracy: 91.67\n",
      "[10,  1750] loss: 0.379 training_accuracy: 75.00\n",
      "[10,  1800] loss: 0.455 training_accuracy: 91.67\n",
      "[10,  1850] loss: 0.429 training_accuracy: 91.67\n",
      "[10,  1900] loss: 0.372 training_accuracy: 66.67\n",
      "[10,  1950] loss: 0.407 training_accuracy: 66.67\n",
      "[10,  2000] loss: 0.379 training_accuracy: 91.67\n",
      "Epoch [10] Loss: 0.392 Training Accuracy: 82.147 Validation Accuracy: 82.496 \n",
      "------------------------------------------------------------------------\n",
      "[11,    50] loss: 0.410 training_accuracy: 83.33\n",
      "[11,   100] loss: 0.401 training_accuracy: 91.67\n",
      "[11,   150] loss: 0.388 training_accuracy: 83.33\n",
      "[11,   200] loss: 0.421 training_accuracy: 83.33\n",
      "[11,   250] loss: 0.378 training_accuracy: 66.67\n",
      "[11,   300] loss: 0.384 training_accuracy: 100.00\n",
      "[11,   350] loss: 0.373 training_accuracy: 83.33\n",
      "[11,   400] loss: 0.448 training_accuracy: 83.33\n",
      "[11,   450] loss: 0.404 training_accuracy: 83.33\n",
      "[11,   500] loss: 0.360 training_accuracy: 83.33\n",
      "[11,   550] loss: 0.404 training_accuracy: 100.00\n",
      "[11,   600] loss: 0.374 training_accuracy: 100.00\n",
      "[11,   650] loss: 0.408 training_accuracy: 83.33\n",
      "[11,   700] loss: 0.375 training_accuracy: 91.67\n",
      "[11,   750] loss: 0.407 training_accuracy: 83.33\n",
      "[11,   800] loss: 0.366 training_accuracy: 75.00\n",
      "[11,   850] loss: 0.380 training_accuracy: 75.00\n",
      "[11,   900] loss: 0.419 training_accuracy: 91.67\n",
      "[11,   950] loss: 0.378 training_accuracy: 91.67\n",
      "[11,  1000] loss: 0.387 training_accuracy: 83.33\n",
      "[11,  1050] loss: 0.382 training_accuracy: 91.67\n",
      "[11,  1100] loss: 0.420 training_accuracy: 83.33\n",
      "[11,  1150] loss: 0.386 training_accuracy: 91.67\n",
      "[11,  1200] loss: 0.363 training_accuracy: 75.00\n",
      "[11,  1250] loss: 0.382 training_accuracy: 66.67\n",
      "[11,  1300] loss: 0.406 training_accuracy: 83.33\n",
      "[11,  1350] loss: 0.385 training_accuracy: 91.67\n",
      "[11,  1400] loss: 0.374 training_accuracy: 66.67\n",
      "[11,  1450] loss: 0.412 training_accuracy: 66.67\n",
      "[11,  1500] loss: 0.367 training_accuracy: 91.67\n",
      "[11,  1550] loss: 0.410 training_accuracy: 58.33\n",
      "[11,  1600] loss: 0.412 training_accuracy: 83.33\n",
      "[11,  1650] loss: 0.365 training_accuracy: 91.67\n",
      "[11,  1700] loss: 0.404 training_accuracy: 100.00\n",
      "[11,  1750] loss: 0.411 training_accuracy: 91.67\n",
      "[11,  1800] loss: 0.422 training_accuracy: 91.67\n",
      "[11,  1850] loss: 0.376 training_accuracy: 91.67\n",
      "[11,  1900] loss: 0.394 training_accuracy: 66.67\n",
      "[11,  1950] loss: 0.384 training_accuracy: 91.67\n",
      "[11,  2000] loss: 0.401 training_accuracy: 66.67\n",
      "Epoch [11] Loss: 0.394 Training Accuracy: 82.151 Validation Accuracy: 81.856 \n",
      "------------------------------------------------------------------------\n",
      "[12,    50] loss: 0.387 training_accuracy: 100.00\n",
      "[12,   100] loss: 0.367 training_accuracy: 75.00\n",
      "[12,   150] loss: 0.379 training_accuracy: 75.00\n",
      "[12,   200] loss: 0.414 training_accuracy: 83.33\n",
      "[12,   250] loss: 0.422 training_accuracy: 83.33\n",
      "[12,   300] loss: 0.396 training_accuracy: 66.67\n",
      "[12,   350] loss: 0.384 training_accuracy: 100.00\n",
      "[12,   400] loss: 0.389 training_accuracy: 91.67\n",
      "[12,   450] loss: 0.369 training_accuracy: 75.00\n",
      "[12,   500] loss: 0.404 training_accuracy: 75.00\n",
      "[12,   550] loss: 0.403 training_accuracy: 75.00\n",
      "[12,   600] loss: 0.342 training_accuracy: 91.67\n",
      "[12,   650] loss: 0.410 training_accuracy: 91.67\n",
      "[12,   700] loss: 0.399 training_accuracy: 100.00\n",
      "[12,   750] loss: 0.422 training_accuracy: 100.00\n",
      "[12,   800] loss: 0.419 training_accuracy: 66.67\n",
      "[12,   850] loss: 0.359 training_accuracy: 83.33\n",
      "[12,   900] loss: 0.405 training_accuracy: 58.33\n",
      "[12,   950] loss: 0.396 training_accuracy: 91.67\n",
      "[12,  1000] loss: 0.394 training_accuracy: 75.00\n",
      "[12,  1050] loss: 0.366 training_accuracy: 83.33\n",
      "[12,  1100] loss: 0.381 training_accuracy: 91.67\n",
      "[12,  1150] loss: 0.384 training_accuracy: 75.00\n",
      "[12,  1200] loss: 0.429 training_accuracy: 50.00\n",
      "[12,  1250] loss: 0.408 training_accuracy: 83.33\n",
      "[12,  1300] loss: 0.384 training_accuracy: 100.00\n",
      "[12,  1350] loss: 0.394 training_accuracy: 58.33\n",
      "[12,  1400] loss: 0.379 training_accuracy: 100.00\n",
      "[12,  1450] loss: 0.385 training_accuracy: 100.00\n",
      "[12,  1500] loss: 0.356 training_accuracy: 83.33\n",
      "[12,  1550] loss: 0.368 training_accuracy: 75.00\n",
      "[12,  1600] loss: 0.355 training_accuracy: 66.67\n",
      "[12,  1650] loss: 0.369 training_accuracy: 75.00\n",
      "[12,  1700] loss: 0.412 training_accuracy: 83.33\n",
      "[12,  1750] loss: 0.404 training_accuracy: 75.00\n",
      "[12,  1800] loss: 0.411 training_accuracy: 41.67\n",
      "[12,  1850] loss: 0.412 training_accuracy: 66.67\n",
      "[12,  1900] loss: 0.381 training_accuracy: 66.67\n",
      "[12,  1950] loss: 0.406 training_accuracy: 75.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12,  2000] loss: 0.380 training_accuracy: 75.00\n",
      "Epoch [12] Loss: 0.380 Training Accuracy: 82.833 Validation Accuracy: 83.091 \n",
      "------------------------------------------------------------------------\n",
      "[13,    50] loss: 0.378 training_accuracy: 91.67\n",
      "[13,   100] loss: 0.345 training_accuracy: 75.00\n",
      "[13,   150] loss: 0.393 training_accuracy: 91.67\n",
      "[13,   200] loss: 0.306 training_accuracy: 83.33\n",
      "[13,   250] loss: 0.402 training_accuracy: 75.00\n",
      "[13,   300] loss: 0.364 training_accuracy: 75.00\n",
      "[13,   350] loss: 0.348 training_accuracy: 91.67\n",
      "[13,   400] loss: 0.406 training_accuracy: 83.33\n",
      "[13,   450] loss: 0.385 training_accuracy: 75.00\n",
      "[13,   500] loss: 0.397 training_accuracy: 75.00\n",
      "[13,   550] loss: 0.400 training_accuracy: 66.67\n",
      "[13,   600] loss: 0.392 training_accuracy: 75.00\n",
      "[13,   650] loss: 0.369 training_accuracy: 100.00\n",
      "[13,   700] loss: 0.420 training_accuracy: 83.33\n",
      "[13,   750] loss: 0.419 training_accuracy: 75.00\n",
      "[13,   800] loss: 0.367 training_accuracy: 66.67\n",
      "[13,   850] loss: 0.365 training_accuracy: 83.33\n",
      "[13,   900] loss: 0.354 training_accuracy: 83.33\n",
      "[13,   950] loss: 0.388 training_accuracy: 91.67\n",
      "[13,  1000] loss: 0.405 training_accuracy: 83.33\n",
      "[13,  1050] loss: 0.423 training_accuracy: 75.00\n",
      "[13,  1100] loss: 0.407 training_accuracy: 66.67\n",
      "[13,  1150] loss: 0.401 training_accuracy: 91.67\n",
      "[13,  1200] loss: 0.391 training_accuracy: 75.00\n",
      "[13,  1250] loss: 0.389 training_accuracy: 75.00\n",
      "[13,  1300] loss: 0.402 training_accuracy: 83.33\n",
      "[13,  1350] loss: 0.353 training_accuracy: 91.67\n",
      "[13,  1400] loss: 0.430 training_accuracy: 83.33\n",
      "[13,  1450] loss: 0.425 training_accuracy: 83.33\n",
      "[13,  1500] loss: 0.398 training_accuracy: 91.67\n",
      "[13,  1550] loss: 0.413 training_accuracy: 83.33\n",
      "[13,  1600] loss: 0.347 training_accuracy: 91.67\n",
      "[13,  1650] loss: 0.393 training_accuracy: 83.33\n",
      "[13,  1700] loss: 0.385 training_accuracy: 91.67\n",
      "[13,  1750] loss: 0.389 training_accuracy: 91.67\n",
      "[13,  1800] loss: 0.391 training_accuracy: 91.67\n",
      "[13,  1850] loss: 0.387 training_accuracy: 83.33\n",
      "[13,  1900] loss: 0.392 training_accuracy: 75.00\n",
      "[13,  1950] loss: 0.389 training_accuracy: 91.67\n",
      "[13,  2000] loss: 0.406 training_accuracy: 100.00\n",
      "Epoch [13] Loss: 0.382 Training Accuracy: 82.445 Validation Accuracy: 82.700 \n",
      "------------------------------------------------------------------------\n",
      "[14,    50] loss: 0.363 training_accuracy: 91.67\n",
      "[14,   100] loss: 0.430 training_accuracy: 75.00\n",
      "[14,   150] loss: 0.391 training_accuracy: 91.67\n",
      "[14,   200] loss: 0.378 training_accuracy: 91.67\n",
      "[14,   250] loss: 0.387 training_accuracy: 100.00\n",
      "[14,   300] loss: 0.379 training_accuracy: 58.33\n",
      "[14,   350] loss: 0.351 training_accuracy: 91.67\n",
      "[14,   400] loss: 0.365 training_accuracy: 75.00\n",
      "[14,   450] loss: 0.381 training_accuracy: 75.00\n",
      "[14,   500] loss: 0.374 training_accuracy: 75.00\n",
      "[14,   550] loss: 0.383 training_accuracy: 83.33\n",
      "[14,   600] loss: 0.418 training_accuracy: 66.67\n",
      "[14,   650] loss: 0.376 training_accuracy: 83.33\n",
      "[14,   700] loss: 0.406 training_accuracy: 83.33\n",
      "[14,   750] loss: 0.374 training_accuracy: 91.67\n",
      "[14,   800] loss: 0.390 training_accuracy: 83.33\n",
      "[14,   850] loss: 0.367 training_accuracy: 91.67\n",
      "[14,   900] loss: 0.376 training_accuracy: 91.67\n",
      "[14,   950] loss: 0.434 training_accuracy: 83.33\n",
      "[14,  1000] loss: 0.352 training_accuracy: 83.33\n",
      "[14,  1050] loss: 0.408 training_accuracy: 75.00\n",
      "[14,  1100] loss: 0.373 training_accuracy: 100.00\n",
      "[14,  1150] loss: 0.376 training_accuracy: 91.67\n",
      "[14,  1200] loss: 0.373 training_accuracy: 91.67\n",
      "[14,  1250] loss: 0.384 training_accuracy: 83.33\n",
      "[14,  1300] loss: 0.394 training_accuracy: 91.67\n",
      "[14,  1350] loss: 0.407 training_accuracy: 75.00\n",
      "[14,  1400] loss: 0.413 training_accuracy: 83.33\n",
      "[14,  1450] loss: 0.394 training_accuracy: 83.33\n",
      "[14,  1500] loss: 0.384 training_accuracy: 91.67\n",
      "[14,  1550] loss: 0.395 training_accuracy: 91.67\n",
      "[14,  1600] loss: 0.382 training_accuracy: 83.33\n",
      "[14,  1650] loss: 0.381 training_accuracy: 83.33\n",
      "[14,  1700] loss: 0.400 training_accuracy: 83.33\n",
      "[14,  1750] loss: 0.395 training_accuracy: 91.67\n",
      "[14,  1800] loss: 0.381 training_accuracy: 75.00\n",
      "[14,  1850] loss: 0.408 training_accuracy: 91.67\n",
      "[14,  1900] loss: 0.351 training_accuracy: 75.00\n",
      "[14,  1950] loss: 0.373 training_accuracy: 83.33\n",
      "[14,  2000] loss: 0.368 training_accuracy: 75.00\n",
      "Epoch [14] Loss: 0.378 Training Accuracy: 82.647 Validation Accuracy: 82.970 \n",
      "------------------------------------------------------------------------\n",
      "[15,    50] loss: 0.328 training_accuracy: 83.33\n",
      "[15,   100] loss: 0.369 training_accuracy: 58.33\n",
      "[15,   150] loss: 0.412 training_accuracy: 100.00\n",
      "[15,   200] loss: 0.377 training_accuracy: 83.33\n",
      "[15,   250] loss: 0.412 training_accuracy: 91.67\n",
      "[15,   300] loss: 0.422 training_accuracy: 75.00\n",
      "[15,   350] loss: 0.387 training_accuracy: 66.67\n",
      "[15,   400] loss: 0.351 training_accuracy: 83.33\n",
      "[15,   450] loss: 0.364 training_accuracy: 91.67\n",
      "[15,   500] loss: 0.399 training_accuracy: 75.00\n",
      "[15,   550] loss: 0.351 training_accuracy: 83.33\n",
      "[15,   600] loss: 0.384 training_accuracy: 91.67\n",
      "[15,   650] loss: 0.343 training_accuracy: 83.33\n",
      "[15,   700] loss: 0.429 training_accuracy: 75.00\n",
      "[15,   750] loss: 0.395 training_accuracy: 75.00\n",
      "[15,   800] loss: 0.390 training_accuracy: 58.33\n",
      "[15,   850] loss: 0.389 training_accuracy: 66.67\n",
      "[15,   900] loss: 0.402 training_accuracy: 75.00\n",
      "[15,   950] loss: 0.399 training_accuracy: 75.00\n",
      "[15,  1000] loss: 0.339 training_accuracy: 91.67\n",
      "[15,  1050] loss: 0.386 training_accuracy: 75.00\n",
      "[15,  1100] loss: 0.346 training_accuracy: 100.00\n",
      "[15,  1150] loss: 0.427 training_accuracy: 58.33\n",
      "[15,  1200] loss: 0.448 training_accuracy: 66.67\n",
      "[15,  1250] loss: 0.387 training_accuracy: 83.33\n",
      "[15,  1300] loss: 0.401 training_accuracy: 100.00\n",
      "[15,  1350] loss: 0.352 training_accuracy: 91.67\n",
      "[15,  1400] loss: 0.395 training_accuracy: 83.33\n",
      "[15,  1450] loss: 0.371 training_accuracy: 100.00\n",
      "[15,  1500] loss: 0.393 training_accuracy: 66.67\n",
      "[15,  1550] loss: 0.387 training_accuracy: 75.00\n",
      "[15,  1600] loss: 0.414 training_accuracy: 100.00\n",
      "[15,  1650] loss: 0.382 training_accuracy: 91.67\n",
      "[15,  1700] loss: 0.356 training_accuracy: 75.00\n",
      "[15,  1750] loss: 0.348 training_accuracy: 83.33\n",
      "[15,  1800] loss: 0.389 training_accuracy: 91.67\n",
      "[15,  1850] loss: 0.350 training_accuracy: 91.67\n",
      "[15,  1900] loss: 0.417 training_accuracy: 75.00\n",
      "[15,  1950] loss: 0.393 training_accuracy: 91.67\n",
      "[15,  2000] loss: 0.347 training_accuracy: 66.67\n",
      "Epoch [15] Loss: 0.380 Training Accuracy: 82.515 Validation Accuracy: 83.218 \n",
      "------------------------------------------------------------------------\n",
      "[16,    50] loss: 0.400 training_accuracy: 66.67\n",
      "[16,   100] loss: 0.381 training_accuracy: 83.33\n",
      "[16,   150] loss: 0.419 training_accuracy: 75.00\n",
      "[16,   200] loss: 0.343 training_accuracy: 91.67\n",
      "[16,   250] loss: 0.385 training_accuracy: 91.67\n",
      "[16,   300] loss: 0.400 training_accuracy: 100.00\n",
      "[16,   350] loss: 0.420 training_accuracy: 66.67\n",
      "[16,   400] loss: 0.405 training_accuracy: 75.00\n",
      "[16,   450] loss: 0.416 training_accuracy: 91.67\n",
      "[16,   500] loss: 0.364 training_accuracy: 83.33\n",
      "[16,   550] loss: 0.370 training_accuracy: 100.00\n",
      "[16,   600] loss: 0.368 training_accuracy: 83.33\n",
      "[16,   650] loss: 0.409 training_accuracy: 91.67\n",
      "[16,   700] loss: 0.337 training_accuracy: 91.67\n",
      "[16,   750] loss: 0.345 training_accuracy: 83.33\n",
      "[16,   800] loss: 0.367 training_accuracy: 83.33\n",
      "[16,   850] loss: 0.399 training_accuracy: 91.67\n",
      "[16,   900] loss: 0.350 training_accuracy: 83.33\n",
      "[16,   950] loss: 0.373 training_accuracy: 91.67\n",
      "[16,  1000] loss: 0.383 training_accuracy: 83.33\n",
      "[16,  1050] loss: 0.414 training_accuracy: 83.33\n",
      "[16,  1100] loss: 0.401 training_accuracy: 75.00\n",
      "[16,  1150] loss: 0.404 training_accuracy: 75.00\n",
      "[16,  1200] loss: 0.419 training_accuracy: 83.33\n",
      "[16,  1250] loss: 0.399 training_accuracy: 83.33\n",
      "[16,  1300] loss: 0.377 training_accuracy: 83.33\n",
      "[16,  1350] loss: 0.422 training_accuracy: 66.67\n",
      "[16,  1400] loss: 0.367 training_accuracy: 83.33\n",
      "[16,  1450] loss: 0.387 training_accuracy: 75.00\n",
      "[16,  1500] loss: 0.378 training_accuracy: 91.67\n",
      "[16,  1550] loss: 0.393 training_accuracy: 75.00\n",
      "[16,  1600] loss: 0.396 training_accuracy: 100.00\n",
      "[16,  1650] loss: 0.365 training_accuracy: 91.67\n",
      "[16,  1700] loss: 0.393 training_accuracy: 75.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16,  1750] loss: 0.314 training_accuracy: 100.00\n",
      "[16,  1800] loss: 0.367 training_accuracy: 75.00\n",
      "[16,  1850] loss: 0.381 training_accuracy: 83.33\n",
      "[16,  1900] loss: 0.364 training_accuracy: 83.33\n",
      "[16,  1950] loss: 0.333 training_accuracy: 91.67\n",
      "[16,  2000] loss: 0.389 training_accuracy: 100.00\n",
      "Epoch [16] Loss: 0.370 Training Accuracy: 83.164 Validation Accuracy: 83.444 \n",
      "------------------------------------------------------------------------\n",
      "[17,    50] loss: 0.349 training_accuracy: 91.67\n",
      "[17,   100] loss: 0.381 training_accuracy: 66.67\n",
      "[17,   150] loss: 0.391 training_accuracy: 75.00\n",
      "[17,   200] loss: 0.354 training_accuracy: 83.33\n",
      "[17,   250] loss: 0.397 training_accuracy: 83.33\n",
      "[17,   300] loss: 0.381 training_accuracy: 83.33\n",
      "[17,   350] loss: 0.357 training_accuracy: 83.33\n",
      "[17,   400] loss: 0.379 training_accuracy: 91.67\n",
      "[17,   450] loss: 0.369 training_accuracy: 83.33\n",
      "[17,   500] loss: 0.411 training_accuracy: 75.00\n",
      "[17,   550] loss: 0.393 training_accuracy: 83.33\n",
      "[17,   600] loss: 0.377 training_accuracy: 83.33\n",
      "[17,   650] loss: 0.344 training_accuracy: 91.67\n",
      "[17,   700] loss: 0.405 training_accuracy: 66.67\n",
      "[17,   750] loss: 0.355 training_accuracy: 91.67\n",
      "[17,   800] loss: 0.360 training_accuracy: 75.00\n",
      "[17,   850] loss: 0.361 training_accuracy: 91.67\n",
      "[17,   900] loss: 0.389 training_accuracy: 66.67\n",
      "[17,   950] loss: 0.386 training_accuracy: 66.67\n",
      "[17,  1000] loss: 0.369 training_accuracy: 75.00\n",
      "[17,  1050] loss: 0.360 training_accuracy: 75.00\n",
      "[17,  1100] loss: 0.389 training_accuracy: 91.67\n",
      "[17,  1150] loss: 0.398 training_accuracy: 83.33\n",
      "[17,  1200] loss: 0.375 training_accuracy: 66.67\n",
      "[17,  1250] loss: 0.361 training_accuracy: 91.67\n",
      "[17,  1300] loss: 0.399 training_accuracy: 66.67\n",
      "[17,  1350] loss: 0.358 training_accuracy: 83.33\n",
      "[17,  1400] loss: 0.358 training_accuracy: 83.33\n",
      "[17,  1450] loss: 0.374 training_accuracy: 91.67\n",
      "[17,  1500] loss: 0.360 training_accuracy: 91.67\n",
      "[17,  1550] loss: 0.389 training_accuracy: 83.33\n",
      "[17,  1600] loss: 0.434 training_accuracy: 83.33\n",
      "[17,  1650] loss: 0.376 training_accuracy: 66.67\n",
      "[17,  1700] loss: 0.356 training_accuracy: 66.67\n",
      "[17,  1750] loss: 0.406 training_accuracy: 75.00\n",
      "[17,  1800] loss: 0.403 training_accuracy: 83.33\n",
      "[17,  1850] loss: 0.357 training_accuracy: 91.67\n",
      "[17,  1900] loss: 0.342 training_accuracy: 83.33\n",
      "[17,  1950] loss: 0.400 training_accuracy: 83.33\n",
      "[17,  2000] loss: 0.387 training_accuracy: 83.33\n",
      "Epoch [17] Loss: 0.378 Training Accuracy: 82.540 Validation Accuracy: 82.666 \n",
      "------------------------------------------------------------------------\n",
      "[18,    50] loss: 0.381 training_accuracy: 100.00\n",
      "[18,   100] loss: 0.348 training_accuracy: 91.67\n",
      "[18,   150] loss: 0.398 training_accuracy: 83.33\n",
      "[18,   200] loss: 0.392 training_accuracy: 100.00\n",
      "[18,   250] loss: 0.388 training_accuracy: 66.67\n",
      "[18,   300] loss: 0.393 training_accuracy: 75.00\n",
      "[18,   350] loss: 0.391 training_accuracy: 83.33\n",
      "[18,   400] loss: 0.391 training_accuracy: 75.00\n",
      "[18,   450] loss: 0.374 training_accuracy: 75.00\n",
      "[18,   500] loss: 0.435 training_accuracy: 83.33\n",
      "[18,   550] loss: 0.373 training_accuracy: 91.67\n",
      "[18,   600] loss: 0.388 training_accuracy: 83.33\n",
      "[18,   650] loss: 0.346 training_accuracy: 75.00\n",
      "[18,   700] loss: 0.407 training_accuracy: 83.33\n",
      "[18,   750] loss: 0.386 training_accuracy: 91.67\n",
      "[18,   800] loss: 0.394 training_accuracy: 91.67\n",
      "[18,   850] loss: 0.429 training_accuracy: 83.33\n",
      "[18,   900] loss: 0.368 training_accuracy: 91.67\n",
      "[18,   950] loss: 0.386 training_accuracy: 66.67\n",
      "[18,  1000] loss: 0.371 training_accuracy: 83.33\n",
      "[18,  1050] loss: 0.348 training_accuracy: 83.33\n",
      "[18,  1100] loss: 0.389 training_accuracy: 100.00\n",
      "[18,  1150] loss: 0.323 training_accuracy: 91.67\n",
      "[18,  1200] loss: 0.349 training_accuracy: 83.33\n",
      "[18,  1250] loss: 0.390 training_accuracy: 100.00\n",
      "[18,  1300] loss: 0.357 training_accuracy: 75.00\n",
      "[18,  1350] loss: 0.384 training_accuracy: 91.67\n",
      "[18,  1400] loss: 0.344 training_accuracy: 83.33\n",
      "[18,  1450] loss: 0.374 training_accuracy: 75.00\n",
      "[18,  1500] loss: 0.383 training_accuracy: 83.33\n",
      "[18,  1550] loss: 0.332 training_accuracy: 75.00\n",
      "[18,  1600] loss: 0.348 training_accuracy: 91.67\n",
      "[18,  1650] loss: 0.363 training_accuracy: 83.33\n",
      "[18,  1700] loss: 0.386 training_accuracy: 75.00\n",
      "[18,  1750] loss: 0.381 training_accuracy: 91.67\n",
      "[18,  1800] loss: 0.408 training_accuracy: 100.00\n",
      "[18,  1850] loss: 0.334 training_accuracy: 91.67\n",
      "[18,  1900] loss: 0.401 training_accuracy: 75.00\n",
      "[18,  1950] loss: 0.355 training_accuracy: 83.33\n",
      "[18,  2000] loss: 0.406 training_accuracy: 100.00\n",
      "Epoch [18] Loss: 0.374 Training Accuracy: 83.015 Validation Accuracy: 83.229 \n",
      "------------------------------------------------------------------------\n",
      "[19,    50] loss: 0.353 training_accuracy: 66.67\n",
      "[19,   100] loss: 0.363 training_accuracy: 91.67\n",
      "[19,   150] loss: 0.389 training_accuracy: 75.00\n",
      "[19,   200] loss: 0.413 training_accuracy: 66.67\n",
      "[19,   250] loss: 0.402 training_accuracy: 83.33\n",
      "[19,   300] loss: 0.398 training_accuracy: 83.33\n",
      "[19,   350] loss: 0.420 training_accuracy: 91.67\n",
      "[19,   400] loss: 0.341 training_accuracy: 83.33\n",
      "[19,   450] loss: 0.358 training_accuracy: 75.00\n",
      "[19,   500] loss: 0.381 training_accuracy: 91.67\n",
      "[19,   550] loss: 0.410 training_accuracy: 83.33\n",
      "[19,   600] loss: 0.365 training_accuracy: 75.00\n",
      "[19,   650] loss: 0.372 training_accuracy: 83.33\n",
      "[19,   700] loss: 0.359 training_accuracy: 83.33\n",
      "[19,   750] loss: 0.385 training_accuracy: 100.00\n",
      "[19,   800] loss: 0.375 training_accuracy: 75.00\n",
      "[19,   850] loss: 0.353 training_accuracy: 83.33\n",
      "[19,   900] loss: 0.395 training_accuracy: 75.00\n",
      "[19,   950] loss: 0.332 training_accuracy: 83.33\n",
      "[19,  1000] loss: 0.360 training_accuracy: 66.67\n",
      "[19,  1050] loss: 0.358 training_accuracy: 91.67\n",
      "[19,  1100] loss: 0.404 training_accuracy: 75.00\n",
      "[19,  1150] loss: 0.377 training_accuracy: 83.33\n",
      "[19,  1200] loss: 0.399 training_accuracy: 75.00\n",
      "[19,  1250] loss: 0.386 training_accuracy: 83.33\n",
      "[19,  1300] loss: 0.389 training_accuracy: 75.00\n",
      "[19,  1350] loss: 0.378 training_accuracy: 91.67\n",
      "[19,  1400] loss: 0.379 training_accuracy: 75.00\n",
      "[19,  1450] loss: 0.356 training_accuracy: 83.33\n",
      "[19,  1500] loss: 0.374 training_accuracy: 91.67\n",
      "[19,  1550] loss: 0.379 training_accuracy: 75.00\n",
      "[19,  1600] loss: 0.391 training_accuracy: 91.67\n",
      "[19,  1650] loss: 0.370 training_accuracy: 66.67\n",
      "[19,  1700] loss: 0.353 training_accuracy: 100.00\n",
      "[19,  1750] loss: 0.367 training_accuracy: 83.33\n",
      "[19,  1800] loss: 0.384 training_accuracy: 83.33\n",
      "[19,  1850] loss: 0.334 training_accuracy: 75.00\n",
      "[19,  1900] loss: 0.365 training_accuracy: 91.67\n",
      "[19,  1950] loss: 0.432 training_accuracy: 83.33\n",
      "[19,  2000] loss: 0.358 training_accuracy: 75.00\n",
      "Epoch [19] Loss: 0.385 Training Accuracy: 82.354 Validation Accuracy: 82.931 \n",
      "------------------------------------------------------------------------\n",
      "[20,    50] loss: 0.377 training_accuracy: 66.67\n",
      "[20,   100] loss: 0.390 training_accuracy: 75.00\n",
      "[20,   150] loss: 0.403 training_accuracy: 83.33\n",
      "[20,   200] loss: 0.347 training_accuracy: 58.33\n",
      "[20,   250] loss: 0.369 training_accuracy: 75.00\n",
      "[20,   300] loss: 0.334 training_accuracy: 66.67\n",
      "[20,   350] loss: 0.342 training_accuracy: 91.67\n",
      "[20,   400] loss: 0.407 training_accuracy: 58.33\n",
      "[20,   450] loss: 0.378 training_accuracy: 83.33\n",
      "[20,   500] loss: 0.402 training_accuracy: 100.00\n",
      "[20,   550] loss: 0.397 training_accuracy: 91.67\n",
      "[20,   600] loss: 0.374 training_accuracy: 83.33\n",
      "[20,   650] loss: 0.332 training_accuracy: 91.67\n",
      "[20,   700] loss: 0.378 training_accuracy: 100.00\n",
      "[20,   750] loss: 0.378 training_accuracy: 83.33\n",
      "[20,   800] loss: 0.403 training_accuracy: 66.67\n",
      "[20,   850] loss: 0.316 training_accuracy: 83.33\n",
      "[20,   900] loss: 0.362 training_accuracy: 91.67\n",
      "[20,   950] loss: 0.372 training_accuracy: 83.33\n",
      "[20,  1000] loss: 0.405 training_accuracy: 50.00\n",
      "[20,  1050] loss: 0.379 training_accuracy: 100.00\n",
      "[20,  1100] loss: 0.362 training_accuracy: 91.67\n",
      "[20,  1150] loss: 0.364 training_accuracy: 91.67\n",
      "[20,  1200] loss: 0.378 training_accuracy: 91.67\n",
      "[20,  1250] loss: 0.397 training_accuracy: 75.00\n",
      "[20,  1300] loss: 0.378 training_accuracy: 100.00\n",
      "[20,  1350] loss: 0.353 training_accuracy: 83.33\n",
      "[20,  1400] loss: 0.375 training_accuracy: 83.33\n",
      "[20,  1450] loss: 0.371 training_accuracy: 83.33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20,  1500] loss: 0.401 training_accuracy: 91.67\n",
      "[20,  1550] loss: 0.386 training_accuracy: 75.00\n",
      "[20,  1600] loss: 0.371 training_accuracy: 91.67\n",
      "[20,  1650] loss: 0.386 training_accuracy: 66.67\n",
      "[20,  1700] loss: 0.358 training_accuracy: 75.00\n",
      "[20,  1750] loss: 0.363 training_accuracy: 91.67\n",
      "[20,  1800] loss: 0.426 training_accuracy: 75.00\n",
      "[20,  1850] loss: 0.364 training_accuracy: 91.67\n",
      "[20,  1900] loss: 0.362 training_accuracy: 75.00\n",
      "[20,  1950] loss: 0.363 training_accuracy: 75.00\n",
      "[20,  2000] loss: 0.371 training_accuracy: 91.67\n",
      "Epoch [20] Loss: 0.368 Training Accuracy: 83.189 Validation Accuracy: 83.344 \n",
      "------------------------------------------------------------------------\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    running_train_acc = 0.0\n",
    "    running_val_acc = 0.0\n",
    "    running_loss_full = 0.0\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[\"image\"], data[\"opacity_class\"]\n",
    "        inputs, labels = Variable(inputs.cuda(), requires_grad=True), Variable(labels.cuda())\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 50 == 49:    # print every 2000 mini-batches          \n",
    "            train_acc = multi_acc(outputs, labels)\n",
    "            print(\"[%d, %5d] loss: %.3f training_accuracy: %.2f\" % (epoch + 1, i + 1, running_loss / 50, train_acc))\n",
    "            running_loss = 0.0\n",
    "       \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[\"image\"], data[\"opacity_class\"]\n",
    "        inputs, labels = Variable(inputs.cuda(), requires_grad=True), Variable(labels.cuda())\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss_full += loss.item()\n",
    "        running_train_acc += multi_acc(outputs, labels)\n",
    "        \n",
    "    for i, data in enumerate(validation_loader, 0):\n",
    "        inputs, labels = data[\"image\"], data[\"opacity_class\"]\n",
    "        inputs, labels = Variable(inputs.cuda(), requires_grad=True), Variable(labels.cuda())\n",
    "        outputs = model(inputs)\n",
    "        running_val_acc += multi_acc(outputs, labels)\n",
    "        \n",
    "    curr_train_loss = running_loss_full / len(train_loader)    \n",
    "    train_acc = running_train_acc / len(train_loader)\n",
    "    val_acc = running_val_acc / len(validation_loader)\n",
    "    \n",
    "    losses.append(curr_train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_accuracies.append(val_acc)\n",
    "        \n",
    "    print(\"Epoch [%d] Loss: %.3f Training Accuracy: %.3f Validation Accuracy: %.3f \" % (epoch + 1, curr_train_loss, train_acc, val_acc))            \n",
    "    print(\"------------------------------------------------------------------------\")\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T05:28:31.348847Z",
     "start_time": "2020-05-22T05:28:31.341849Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(zip(losses, train_accuracies, val_accuracies), columns=[\"Loss\", \"Train Acc\", \"Val Acc\"])\n",
    "df.to_csv(\"resnet-dataloader-fix-affine-rotate-all-data-pretrained.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T05:28:31.717728Z",
     "start_time": "2020-05-22T05:28:31.666745Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'resnet-dataloader-fix-affine-rotate-all-data-pretrained.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Val/Train/Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T19:28:51.201754Z",
     "start_time": "2020-05-21T19:28:51.066797Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_accuracies, label=\"Training Accuracy\")\n",
    "plt.plot(val_accuracies, label=\"Validation Accuracy\")\n",
    "# plt.plot(losses, label=\"Loss\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0,100)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T06:10:53.023178Z",
     "start_time": "2020-05-22T06:10:52.951201Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"resnet-dataloader-fix-affine-rotate-all-data-pretrained.pth\"))\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T06:22:55.781947Z",
     "start_time": "2020-05-22T06:20:40.724343Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invalid dimension\n",
      "invalid dimension\n",
      "invalid dimension\n",
      "\n",
      "pred 0,label 0 3754\n",
      "pred 0,label 1 618\n",
      "pred 1,label 0 387\n",
      "pred 1,label 1 1286\n",
      "\n",
      "pred 0,label 0 {'Lung Opacity': 0, 'Normal': 1776, 'No Lung Opacity / Not Normal': 1978}\n",
      "pred 0,label 1 {'Lung Opacity': 618, 'Normal': 0, 'No Lung Opacity / Not Normal': 0}\n",
      "pred 1,label 0 {'Lung Opacity': 0, 'Normal': 4, 'No Lung Opacity / Not Normal': 383}\n",
      "pred 1,label 1 {'Lung Opacity': 1286, 'Normal': 0, 'No Lung Opacity / Not Normal': 0}\n"
     ]
    }
   ],
   "source": [
    "results = {\n",
    "    \"pred 0,label 0\": 0,\n",
    "    \"pred 0,label 1\": 0,\n",
    "    \"pred 1,label 0\": 0,\n",
    "    \"pred 1,label 1\": 0\n",
    "}\n",
    "\n",
    "results_classes = {\n",
    "    \"pred 0,label 0\": {\n",
    "        \"Lung Opacity\": 0,\n",
    "        \"Normal\": 0,\n",
    "        \"No Lung Opacity / Not Normal\": 0\n",
    "    },\n",
    "    \"pred 0,label 1\": {\n",
    "        \"Lung Opacity\": 0,\n",
    "        \"Normal\": 0,\n",
    "        \"No Lung Opacity / Not Normal\": 0\n",
    "    },\n",
    "    \"pred 1,label 0\": {\n",
    "        \"Lung Opacity\": 0,\n",
    "        \"Normal\": 0,\n",
    "        \"No Lung Opacity / Not Normal\": 0\n",
    "    },\n",
    "    \"pred 1,label 1\": {\n",
    "        \"Lung Opacity\": 0,\n",
    "        \"Normal\": 0,\n",
    "        \"No Lung Opacity / Not Normal\": 0\n",
    "    }\n",
    "}\n",
    "\n",
    "for i, data in enumerate(validation_loader, 0):\n",
    "    inputs, labels, classes = data[\"image\"], data[\"opacity_class\"], data[\"class\"]\n",
    "    inputs, labels = Variable(inputs.cuda(), requires_grad=True), Variable(labels.cuda())\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    y_pred_softmax = torch.log_softmax(outputs, dim=1)\n",
    "    _, y_pred_tags = torch.max(y_pred_softmax, dim=1)\n",
    "\n",
    "    correct_pred = (y_pred_tags == labels).float()\n",
    "    \n",
    "    for j in range(batch_size):\n",
    "        try:\n",
    "            pattern = \"pred %d,label %d\" % (get_num_from_tensor(y_pred_tags[j]), get_num_from_tensor(labels[j]))\n",
    "            results[pattern] += 1\n",
    "            results_classes[pattern][classes[j]] += 1\n",
    "        except Exception as e:\n",
    "            print(\"invalid dimension\")\n",
    "print()\n",
    "            \n",
    "for key, value in results.items():\n",
    "    print(key, value)\n",
    "    \n",
    "print()\n",
    "    \n",
    "for key, value in results_classes.items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T06:23:26.858962Z",
     "start_time": "2020-05-22T06:23:26.843967Z"
    }
   },
   "outputs": [],
   "source": [
    "def custom_imshow(img, title):\n",
    "    \"\"\"Custom function to display the image using matplotlib\"\"\"\n",
    "\n",
    "    # define std correction to be made\n",
    "    std_correction = np.asarray([0.229, 0.224, 0.225]).reshape(3, 1, 1)\n",
    "\n",
    "    # define mean correction to be made\n",
    "    mean_correction = np.asarray([0.485, 0.456, 0.406]).reshape(3, 1, 1)\n",
    "\n",
    "    # convert the tensor img to numpy img and de normalize\n",
    "    npimg = np.multiply(img.numpy(), std_correction) + mean_correction\n",
    "\n",
    "    # plot the numpy image\n",
    "    plt.figure(figsize=(batch_size * 4, 4))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_filters_multi_channel(t):\n",
    "\n",
    "    # get the number of kernals\n",
    "    num_kernels = t.shape[0]\n",
    "\n",
    "    # define number of columns for subplots\n",
    "    num_cols = 12\n",
    "    # rows = num of kernels\n",
    "    num_rows = num_kernels\n",
    "\n",
    "    # set the figure size\n",
    "    fig = plt.figure(figsize=(num_cols, num_rows))\n",
    "\n",
    "    # looping through all the kernels\n",
    "    for i in range(t.shape[0]):\n",
    "        ax1 = fig.add_subplot(num_rows, num_cols, i+1)\n",
    "\n",
    "        # for each kernel, we convert the tensor to numpy\n",
    "        npimg = np.array(t[i].numpy(), np.float32)\n",
    "        # standardize the numpy image\n",
    "        npimg = (npimg - np.mean(npimg)) / np.std(npimg)\n",
    "        npimg = np.minimum(1, np.maximum(0, (npimg + 0.5)))\n",
    "        npimg = npimg.transpose((1, 2, 0))\n",
    "        ax1.imshow(npimg)\n",
    "        ax1.axis('off')\n",
    "        ax1.set_title(str(i))\n",
    "        ax1.set_xticklabels([])\n",
    "        ax1.set_yticklabels([])\n",
    "\n",
    "    plt.savefig('myimage.png', dpi=100)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_weights(model, layer_num, model_type, single_channel=True, collated=False):\n",
    "\n",
    "    # extracting the model features at the particular layer number\n",
    "    if model_type == \"resnet\":\n",
    "        layer = list(model.children())[layer_num]\n",
    "    else:\n",
    "        layer = model.features[layer_num]\n",
    "        \n",
    "    # checking whether the layer is convolution layer or not\n",
    "    if isinstance(layer, nn.Conv2d):\n",
    "        # getting the weight tensor data\n",
    "        if model_type == \"resnet\":\n",
    "            weight_tensor = list(model.children())[layer_num].weight.data\n",
    "        else:\n",
    "            weight_tensor = model.features[layer_num].weight.data\n",
    "            \n",
    "        if single_channel:\n",
    "            if collated:\n",
    "                plot_filters_single_channel_big(weight_tensor)\n",
    "            else:\n",
    "                plot_filters_single_channel(weight_tensor)\n",
    "\n",
    "        else:\n",
    "            if weight_tensor.shape[1] == 3:\n",
    "                plot_filters_multi_channel(weight_tensor.cpu())\n",
    "            else:\n",
    "                print(\"Can only plot weights with three channels with single channel = False\")\n",
    "\n",
    "    else:\n",
    "        print(\"Can only visualize layers which are convolutional\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T06:23:29.459127Z",
     "start_time": "2020-05-22T06:23:27.232842Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x4608 with 64 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_weights(model, 0, \"resnet\", single_channel = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "678px",
    "left": "84px",
    "top": "110px",
    "width": "212.125px"
   },
   "toc_section_display": false,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

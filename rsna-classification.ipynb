{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T05:29:54.604249Z",
     "start_time": "2020-05-14T05:29:53.493604Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "C:\\Users\\lasse\\.conda\\envs\\pytorch\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch import tensor\n",
    "from torchvision import transforms, utils\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import pydicom as dicom\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "from glob import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T05:29:54.640239Z",
     "start_time": "2020-05-14T05:29:54.605249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    # you can continue going on here, like cuda:1 cuda:2....etc.\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T05:29:54.646236Z",
     "start_time": "2020-05-14T05:29:54.642237Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join(\".\", \"rsa-pneumonia-data\")\n",
    "\n",
    "TRAIN_IMAGES = os.path.join(DATA_DIR, \"stage_2_train_images\")\n",
    "TEST_IMAGES = os.path.join(DATA_DIR, \"stage_2_test_images\")\n",
    "\n",
    "TRAIN_ANNOTATIONS_FILE = \"stage_2_train_labels.csv\"\n",
    "TRAIN_CLASS_FILE = \"stage_2_detailed_class_info.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T05:29:54.658232Z",
     "start_time": "2020-05-14T05:29:54.648236Z"
    }
   },
   "outputs": [],
   "source": [
    "class OpacityDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, image_dir, subsample, transform=None):\n",
    "        self.classes_df = pd.read_csv(csv_file)\n",
    "        if subsample is not None:\n",
    "            self.classes_df = self.classes_df[:subsample]\n",
    "        self.root_dir = root_dir\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # Convert our classes to integers!\n",
    "        self.class_dict = {\n",
    "            \"Normal\": 0,\n",
    "            \"No Lung Opacity / Not Normal\": 0,\n",
    "            \"Lung Opacity\": 1\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.classes_df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if torch.is_tensor(index):\n",
    "            index = index.tolist()\n",
    "\n",
    "        # Get the image, preprocess it for our model\n",
    "        image_path = os.path.join(\n",
    "            self.image_dir, self.classes_df.iloc[index, 0])\n",
    "        image = dicom.read_file(image_path + \".dcm\").pixel_array\n",
    "        image = image[::4, ::4]\n",
    "        image = image/image.max()\n",
    "        image = (255*image).clip(0, 255).astype(np.uint8)\n",
    "        image = Image.fromarray(image).convert(\"RGB\")\n",
    "        opacity_class = self.classes_df.at[index, 'class']\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        sample = {\"image\": image,\n",
    "                  \"opacity_class\": self.class_dict[opacity_class]}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T05:29:54.691222Z",
     "start_time": "2020-05-14T05:29:54.659232Z"
    }
   },
   "outputs": [],
   "source": [
    "validation_split = 0.2;\n",
    "\n",
    "opacity_dataset = OpacityDataset(\n",
    "    csv_file=os.path.join(DATA_DIR, TRAIN_CLASS_FILE),\n",
    "    root_dir=DATA_DIR,\n",
    "    image_dir=TRAIN_IMAGES,\n",
    "    subsample=8000,\n",
    "#     subsample=None,\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "dataset_size = len(opacity_dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "# np.random.seed(1)\n",
    "# np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Create samplers for data loading\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T05:29:54.697219Z",
     "start_time": "2020-05-14T05:29:54.692222Z"
    },
    "hide_input": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define our NN\n",
    "# class ConvNet(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(ConvNet, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(1, 16, (3, 3))\n",
    "#         self.pool = nn.MaxPool2d((2, 2), 2)\n",
    "#         self.conv2 = nn.Conv2d(16, 32, (3, 3))\n",
    "#         self.conv3 = nn.Conv2d(32, 64, (3, 3))\n",
    "#         self.conv4 = nn.Conv2d(64, 128, (3, 3))\n",
    "#         self.linear1 = nn.Linear(25088, 4086)\n",
    "#         self.linear3 = nn.Linear(4086, 2)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.pool(F.relu(self.conv1(x)))\n",
    "#         x = self.pool(F.relu(self.conv2(x)))\n",
    "#         x = self.pool(F.relu(self.conv3(x)))\n",
    "#         x = self.pool(F.relu(self.conv4(x)))\n",
    "#         x = x.view(x.size()[0], -1)\n",
    "#         x = F.relu(self.linear1(x))\n",
    "#         x = self.linear3(x)\n",
    "#         return x\n",
    "    \n",
    "# class AlexNet(nn.Module):\n",
    "#     def __init__(self, num_classes=2):\n",
    "#         super(AlexNet, self).__init__()\n",
    "#         self.features = nn.Sequential(\n",
    "#             nn.Conv2d(1, 64, kernel_size=11, stride=4, padding=2),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "#             nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "#             nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "#         )\n",
    "#         self.classifier = nn.Sequential(\n",
    "#             nn.Dropout(),\n",
    "#             nn.Linear(256 * 7 * 7, 4096),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Dropout(),\n",
    "#             nn.Linear(4096, 4096),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Linear(4096, num_classes),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.features(x)\n",
    "#         x = x.view(x.size(0), 256 * 7 * 7)\n",
    "#         x = self.classifier(x)\n",
    "#         return x\n",
    "\n",
    "# model = AlexNet()\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T23:49:13.018378Z",
     "start_time": "2020-05-05T23:49:13.015379Z"
    },
    "deletable": false,
    "editable": false,
    "hide_input": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "del model\n",
    "torch.cuda.ipc_collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T05:29:54.702218Z",
     "start_time": "2020-05-14T05:29:54.698219Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "epochs = 10\n",
    "num_classes = 2\n",
    "batch_size = 8\n",
    "learning_rate = .001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T05:29:59.547670Z",
     "start_time": "2020-05-14T05:29:56.723573Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       "  (fc): Linear(in_features=4096, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torchvision.models.vgg11(pretrained=False)\n",
    "model.fc = nn.Linear(4096, num_classes)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T05:23:02.484920Z",
     "start_time": "2020-05-14T05:23:02.481921Z"
    }
   },
   "outputs": [],
   "source": [
    "# model = torchvision.models.resnet18(pretrained=False)\n",
    "# feature_num = model.fc.in_features\n",
    "# model.fc = nn.Linear(feature_num, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T05:30:03.492409Z",
     "start_time": "2020-05-14T05:30:03.486411Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    opacity_dataset, \n",
    "    batch_size=batch_size, \n",
    "    sampler=train_sampler,\n",
    "    num_workers=0\n",
    ")\n",
    "validation_loader = torch.utils.data.DataLoader(\n",
    "    opacity_dataset, \n",
    "    batch_size=batch_size,\n",
    "    sampler=valid_sampler,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T05:30:04.865970Z",
     "start_time": "2020-05-14T05:30:04.861972Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_num_from_tensor(tensorItem):\n",
    "    return tensorItem.cuda().cpu().numpy().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T05:30:05.361812Z",
     "start_time": "2020-05-14T05:30:05.357814Z"
    }
   },
   "outputs": [],
   "source": [
    "def multi_acc(y_pred, y_test):\n",
    "    y_pred_softmax = torch.log_softmax(y_pred, dim=1)\n",
    "    _, y_pred_tags = torch.max(y_pred_softmax, dim=1)\n",
    "\n",
    "    correct_pred = (y_pred_tags == y_test).float()\n",
    "    acc = correct_pred.sum() / len(correct_pred)\n",
    "    acc = acc * 100\n",
    "\n",
    "    return get_num_from_tensor(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T06:14:41.620842Z",
     "start_time": "2020-05-14T05:30:17.274006Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    50] loss: 3.495 training_accuracy: 37.50\n",
      "[1,   100] loss: 0.932 training_accuracy: 100.00\n",
      "[1,   150] loss: 0.785 training_accuracy: 62.50\n",
      "[1,   200] loss: 0.757 training_accuracy: 75.00\n",
      "[1,   250] loss: 0.719 training_accuracy: 37.50\n",
      "[1,   300] loss: 0.694 training_accuracy: 37.50\n",
      "[1,   350] loss: 0.698 training_accuracy: 50.00\n",
      "[1,   400] loss: 0.722 training_accuracy: 50.00\n",
      "[1,   450] loss: 0.693 training_accuracy: 50.00\n",
      "[1,   500] loss: 0.722 training_accuracy: 37.50\n",
      "[1,   550] loss: 0.686 training_accuracy: 50.00\n",
      "[1,   600] loss: 0.692 training_accuracy: 75.00\n",
      "[1,   650] loss: 0.669 training_accuracy: 62.50\n",
      "[1,   700] loss: 0.699 training_accuracy: 62.50\n",
      "[1,   750] loss: 0.687 training_accuracy: 37.50\n",
      "[1,   800] loss: 0.681 training_accuracy: 75.00\n",
      "Finished training\n",
      "Epoch [1] Training Accuracy: 64.656 Validation Accuracy: 56.188 \n",
      "[2,    50] loss: 0.669 training_accuracy: 62.50\n",
      "[2,   100] loss: 0.668 training_accuracy: 75.00\n",
      "[2,   150] loss: 0.685 training_accuracy: 87.50\n",
      "[2,   200] loss: 0.713 training_accuracy: 50.00\n",
      "[2,   250] loss: 0.700 training_accuracy: 50.00\n",
      "[2,   300] loss: 0.661 training_accuracy: 75.00\n",
      "[2,   350] loss: 0.621 training_accuracy: 50.00\n",
      "[2,   400] loss: 0.648 training_accuracy: 62.50\n",
      "[2,   450] loss: 0.637 training_accuracy: 12.50\n",
      "[2,   500] loss: 0.661 training_accuracy: 37.50\n",
      "[2,   550] loss: 0.628 training_accuracy: 87.50\n",
      "[2,   600] loss: 0.572 training_accuracy: 100.00\n",
      "[2,   650] loss: 0.621 training_accuracy: 75.00\n",
      "[2,   700] loss: 0.577 training_accuracy: 50.00\n",
      "[2,   750] loss: 0.579 training_accuracy: 75.00\n",
      "[2,   800] loss: 0.527 training_accuracy: 75.00\n",
      "Finished training\n",
      "Epoch [2] Training Accuracy: 73.609 Validation Accuracy: 75.312 \n",
      "[3,    50] loss: 0.574 training_accuracy: 87.50\n",
      "[3,   100] loss: 0.564 training_accuracy: 62.50\n",
      "[3,   150] loss: 0.553 training_accuracy: 50.00\n",
      "[3,   200] loss: 0.527 training_accuracy: 100.00\n",
      "[3,   250] loss: 0.554 training_accuracy: 100.00\n",
      "[3,   300] loss: 0.566 training_accuracy: 75.00\n",
      "[3,   350] loss: 0.559 training_accuracy: 75.00\n",
      "[3,   400] loss: 0.494 training_accuracy: 75.00\n",
      "[3,   450] loss: 0.580 training_accuracy: 75.00\n",
      "[3,   500] loss: 0.531 training_accuracy: 100.00\n",
      "[3,   550] loss: 0.500 training_accuracy: 75.00\n",
      "[3,   600] loss: 0.538 training_accuracy: 100.00\n",
      "[3,   650] loss: 0.528 training_accuracy: 62.50\n",
      "[3,   700] loss: 0.531 training_accuracy: 62.50\n",
      "[3,   750] loss: 0.570 training_accuracy: 75.00\n",
      "[3,   800] loss: 0.572 training_accuracy: 87.50\n",
      "Finished training\n",
      "Epoch [3] Training Accuracy: 70.375 Validation Accuracy: 66.250 \n",
      "[4,    50] loss: 0.506 training_accuracy: 75.00\n",
      "[4,   100] loss: 0.478 training_accuracy: 50.00\n",
      "[4,   150] loss: 0.507 training_accuracy: 75.00\n",
      "[4,   200] loss: 0.493 training_accuracy: 62.50\n",
      "[4,   250] loss: 0.512 training_accuracy: 87.50\n",
      "[4,   300] loss: 0.541 training_accuracy: 75.00\n",
      "[4,   350] loss: 0.533 training_accuracy: 62.50\n",
      "[4,   400] loss: 0.508 training_accuracy: 62.50\n",
      "[4,   450] loss: 0.501 training_accuracy: 75.00\n",
      "[4,   500] loss: 0.513 training_accuracy: 75.00\n",
      "[4,   550] loss: 0.515 training_accuracy: 37.50\n",
      "[4,   600] loss: 0.513 training_accuracy: 87.50\n",
      "[4,   650] loss: 0.535 training_accuracy: 50.00\n",
      "[4,   700] loss: 0.582 training_accuracy: 87.50\n",
      "[4,   750] loss: 0.504 training_accuracy: 87.50\n",
      "[4,   800] loss: 0.572 training_accuracy: 50.00\n",
      "Finished training\n",
      "Epoch [4] Training Accuracy: 74.938 Validation Accuracy: 76.812 \n",
      "[5,    50] loss: 0.547 training_accuracy: 62.50\n",
      "[5,   100] loss: 0.507 training_accuracy: 50.00\n",
      "[5,   150] loss: 0.549 training_accuracy: 75.00\n",
      "[5,   200] loss: 0.522 training_accuracy: 62.50\n",
      "[5,   250] loss: 0.490 training_accuracy: 62.50\n",
      "[5,   300] loss: 0.482 training_accuracy: 75.00\n",
      "[5,   350] loss: 0.529 training_accuracy: 75.00\n",
      "[5,   400] loss: 0.530 training_accuracy: 87.50\n",
      "[5,   450] loss: 0.525 training_accuracy: 75.00\n",
      "[5,   500] loss: 0.517 training_accuracy: 12.50\n",
      "[5,   550] loss: 0.478 training_accuracy: 87.50\n",
      "[5,   600] loss: 0.494 training_accuracy: 100.00\n",
      "[5,   650] loss: 0.534 training_accuracy: 75.00\n",
      "[5,   700] loss: 0.535 training_accuracy: 75.00\n",
      "[5,   750] loss: 0.508 training_accuracy: 87.50\n",
      "[5,   800] loss: 0.515 training_accuracy: 62.50\n",
      "Finished training\n",
      "Epoch [5] Training Accuracy: 76.266 Validation Accuracy: 78.875 \n",
      "[6,    50] loss: 0.482 training_accuracy: 87.50\n",
      "[6,   100] loss: 0.511 training_accuracy: 87.50\n",
      "[6,   150] loss: 0.454 training_accuracy: 75.00\n",
      "[6,   200] loss: 0.526 training_accuracy: 75.00\n",
      "[6,   250] loss: 0.493 training_accuracy: 75.00\n",
      "[6,   300] loss: 0.499 training_accuracy: 87.50\n",
      "[6,   350] loss: 0.524 training_accuracy: 87.50\n",
      "[6,   400] loss: 0.487 training_accuracy: 100.00\n",
      "[6,   450] loss: 0.535 training_accuracy: 87.50\n",
      "[6,   500] loss: 0.511 training_accuracy: 62.50\n",
      "[6,   550] loss: 0.511 training_accuracy: 87.50\n",
      "[6,   600] loss: 0.524 training_accuracy: 87.50\n",
      "[6,   650] loss: 0.527 training_accuracy: 50.00\n",
      "[6,   700] loss: 0.495 training_accuracy: 100.00\n",
      "[6,   750] loss: 0.556 training_accuracy: 75.00\n",
      "[6,   800] loss: 0.514 training_accuracy: 75.00\n",
      "Finished training\n",
      "Epoch [6] Training Accuracy: 77.172 Validation Accuracy: 77.312 \n",
      "[7,    50] loss: 0.488 training_accuracy: 87.50\n",
      "[7,   100] loss: 0.525 training_accuracy: 87.50\n",
      "[7,   150] loss: 0.486 training_accuracy: 100.00\n",
      "[7,   200] loss: 0.526 training_accuracy: 37.50\n",
      "[7,   250] loss: 0.504 training_accuracy: 62.50\n",
      "[7,   300] loss: 0.493 training_accuracy: 50.00\n",
      "[7,   350] loss: 0.484 training_accuracy: 100.00\n",
      "[7,   400] loss: 0.519 training_accuracy: 87.50\n",
      "[7,   450] loss: 0.491 training_accuracy: 87.50\n",
      "[7,   500] loss: 0.531 training_accuracy: 87.50\n",
      "[7,   550] loss: 0.444 training_accuracy: 75.00\n",
      "[7,   600] loss: 0.526 training_accuracy: 75.00\n",
      "[7,   650] loss: 0.510 training_accuracy: 62.50\n",
      "[7,   700] loss: 0.479 training_accuracy: 87.50\n",
      "[7,   750] loss: 0.492 training_accuracy: 75.00\n",
      "[7,   800] loss: 0.505 training_accuracy: 75.00\n",
      "Finished training\n",
      "Epoch [7] Training Accuracy: 76.656 Validation Accuracy: 77.375 \n",
      "[8,    50] loss: 0.524 training_accuracy: 62.50\n",
      "[8,   100] loss: 0.463 training_accuracy: 50.00\n",
      "[8,   150] loss: 0.539 training_accuracy: 100.00\n",
      "[8,   200] loss: 0.546 training_accuracy: 62.50\n",
      "[8,   250] loss: 0.517 training_accuracy: 75.00\n",
      "[8,   300] loss: 0.485 training_accuracy: 75.00\n",
      "[8,   350] loss: 0.514 training_accuracy: 87.50\n",
      "[8,   400] loss: 0.512 training_accuracy: 37.50\n",
      "[8,   450] loss: 0.483 training_accuracy: 62.50\n",
      "[8,   500] loss: 0.460 training_accuracy: 100.00\n",
      "[8,   550] loss: 0.525 training_accuracy: 50.00\n",
      "[8,   600] loss: 0.538 training_accuracy: 75.00\n",
      "[8,   650] loss: 0.422 training_accuracy: 87.50\n",
      "[8,   700] loss: 0.489 training_accuracy: 50.00\n",
      "[8,   750] loss: 0.483 training_accuracy: 87.50\n",
      "[8,   800] loss: 0.521 training_accuracy: 87.50\n",
      "Finished training\n",
      "Epoch [8] Training Accuracy: 75.219 Validation Accuracy: 78.375 \n",
      "[9,    50] loss: 0.481 training_accuracy: 75.00\n",
      "[9,   100] loss: 0.444 training_accuracy: 87.50\n",
      "[9,   150] loss: 0.504 training_accuracy: 100.00\n",
      "[9,   200] loss: 0.523 training_accuracy: 100.00\n",
      "[9,   250] loss: 0.494 training_accuracy: 87.50\n",
      "[9,   300] loss: 0.461 training_accuracy: 75.00\n",
      "[9,   350] loss: 0.474 training_accuracy: 87.50\n",
      "[9,   400] loss: 0.522 training_accuracy: 87.50\n",
      "[9,   450] loss: 0.447 training_accuracy: 87.50\n",
      "[9,   500] loss: 0.558 training_accuracy: 87.50\n",
      "[9,   550] loss: 0.500 training_accuracy: 87.50\n",
      "[9,   600] loss: 0.497 training_accuracy: 62.50\n",
      "[9,   650] loss: 0.461 training_accuracy: 62.50\n",
      "[9,   700] loss: 0.490 training_accuracy: 62.50\n",
      "[9,   750] loss: 0.483 training_accuracy: 87.50\n",
      "[9,   800] loss: 0.539 training_accuracy: 62.50\n",
      "Finished training\n",
      "Epoch [9] Training Accuracy: 77.625 Validation Accuracy: 78.125 \n",
      "[10,    50] loss: 0.513 training_accuracy: 75.00\n",
      "[10,   100] loss: 0.455 training_accuracy: 62.50\n",
      "[10,   150] loss: 0.518 training_accuracy: 62.50\n",
      "[10,   200] loss: 0.506 training_accuracy: 75.00\n",
      "[10,   250] loss: 0.487 training_accuracy: 87.50\n",
      "[10,   300] loss: 0.514 training_accuracy: 100.00\n",
      "[10,   350] loss: 0.499 training_accuracy: 75.00\n",
      "[10,   400] loss: 0.442 training_accuracy: 87.50\n",
      "[10,   450] loss: 0.516 training_accuracy: 75.00\n",
      "[10,   500] loss: 0.524 training_accuracy: 75.00\n",
      "[10,   550] loss: 0.476 training_accuracy: 75.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10,   600] loss: 0.459 training_accuracy: 62.50\n",
      "[10,   650] loss: 0.492 training_accuracy: 75.00\n",
      "[10,   700] loss: 0.470 training_accuracy: 62.50\n",
      "[10,   750] loss: 0.501 training_accuracy: 62.50\n",
      "[10,   800] loss: 0.493 training_accuracy: 62.50\n",
      "Finished training\n",
      "Epoch [10] Training Accuracy: 74.109 Validation Accuracy: 70.562 \n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    running_train_acc = 0.0\n",
    "    running_val_acc = 0.0\n",
    "    running_loss_full = 0.0\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[\"image\"], data[\"opacity_class\"]\n",
    "        inputs, labels = Variable(inputs.cuda(), requires_grad=True), Variable(labels.cuda())\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 50 == 49:    # print every 2000 mini-batches          \n",
    "            train_acc = multi_acc(outputs, labels)\n",
    "            print(\"[%d, %5d] loss: %.3f training_accuracy: %.2f\" % (epoch + 1, i + 1, running_loss / 50, train_acc))\n",
    "            running_loss = 0.0\n",
    "       \n",
    "    print(\"Finished training\")\n",
    "        \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[\"image\"], data[\"opacity_class\"]\n",
    "        inputs, labels = Variable(inputs.cuda(), requires_grad=True), Variable(labels.cuda())\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss_full += loss.item()\n",
    "        running_train_acc += multi_acc(outputs, labels)\n",
    "        \n",
    "    for i, data in enumerate(validation_loader, 0):\n",
    "        inputs, labels = data[\"image\"], data[\"opacity_class\"]\n",
    "        inputs, labels = Variable(inputs.cuda(), requires_grad=True), Variable(labels.cuda())\n",
    "        outputs = model(inputs)\n",
    "        running_val_acc += multi_acc(outputs, labels)\n",
    "        \n",
    "    curr_train_loss = running_loss_full / len(train_loader)    \n",
    "    train_acc = running_train_acc / len(train_loader)\n",
    "    val_acc = running_val_acc / len(validation_loader)\n",
    "    \n",
    "    losses.append(curr_train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_accuracies.append(val_acc)\n",
    "        \n",
    "    print(\"Epoch [%d] Training Accuracy: %.3f Validation Accuracy: %.3f \" % (epoch + 1, train_acc, val_acc))            \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T06:24:34.832312Z",
     "start_time": "2020-05-14T06:24:34.821316Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(zip(train_accuracies, val_accuracies), columns=[\"Train Acc\", \"Val Acc\"])\n",
    "df.to_csv(\"vgg16.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T05:09:57.325236Z",
     "start_time": "2020-05-14T05:07:31.814Z"
    }
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(zip(train_accuracies, val_accuracies), columns=[\"Train Acc\", \"Val Acc\"])\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T05:09:57.326236Z",
     "start_time": "2020-05-14T05:07:31.815Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'resnet18-10-32.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T05:09:57.327236Z",
     "start_time": "2020-05-14T05:07:31.818Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(train_accuracies, label=\"Training Accuracy\")\n",
    "plt.plot(val_accuracies, label=\"Validation Accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0,100)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "### 10 Epochs, 32 Batch, Resnet18\n",
    "* Validation values didn't increase that much past the first epoch\n",
    "* Need to check class imbalance \n",
    "* Need to check the amount of values of each class that I'm missing\n",
    "* Try other models with dropout \n",
    "* Clear indiciation of overfitting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
